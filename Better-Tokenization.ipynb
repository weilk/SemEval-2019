{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from keras.layers import Dropout\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras import optimizers\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>turn1</th>\n",
       "      <th>turn2</th>\n",
       "      <th>turn3</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Don't worry  I'm girl</td>\n",
       "      <td>hmm how do I know if you are</td>\n",
       "      <td>What's ur name?</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>When did I?</td>\n",
       "      <td>saw many times i think -_-</td>\n",
       "      <td>No. I never saw you</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>By</td>\n",
       "      <td>by Google Chrome</td>\n",
       "      <td>Where you live</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>U r ridiculous</td>\n",
       "      <td>I might be ridiculous but I am telling the truth.</td>\n",
       "      <td>U little disgusting whore</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Just for time pass</td>\n",
       "      <td>wt do u do 4 a living then</td>\n",
       "      <td>Maybe</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>I'm a dog person</td>\n",
       "      <td>youre so rude</td>\n",
       "      <td>Whaaaat why</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>So whatsup</td>\n",
       "      <td>Nothing much. Sitting sipping and watching TV....</td>\n",
       "      <td>What are you watching on tv?</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Ok</td>\n",
       "      <td>ok im back!!</td>\n",
       "      <td>So, how are u</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>Really?</td>\n",
       "      <td>really really really really really</td>\n",
       "      <td>Y saying so many times...i can hear you</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>Bay</td>\n",
       "      <td>in the bay</td>\n",
       "      <td>üòò love you</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>I hate my boyfriend</td>\n",
       "      <td>you got a boyfriend?</td>\n",
       "      <td>Yes</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>I will do night.</td>\n",
       "      <td>Alright. Keep me in loop.</td>\n",
       "      <td>Not giving WhatsApp no.</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>Sure go ahead</td>\n",
       "      <td>Many thanks once again!</td>\n",
       "      <td>Love you too</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad bad! That's the bad kind of bad.</td>\n",
       "      <td>I have no gf</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>Ok get it......</td>\n",
       "      <td>I made it an option</td>\n",
       "      <td>Ok</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>Money money and lots of moneyüòçüòç</td>\n",
       "      <td>I need to get it tailored but I'm in love with...</td>\n",
       "      <td>üòÅüòÅ</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>My gf left ne</td>\n",
       "      <td>Get over it. Go out with someone else.</td>\n",
       "      <td>Me*</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>get lost</td>\n",
       "      <td>I know you guys want to loose to me always.</td>\n",
       "      <td>I don't want to talk u any more</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>You are lying and i know that</td>\n",
       "      <td>I KNOW YOU'RE LYING, AB BYS</td>\n",
       "      <td>üò≠üò≠</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>Ur creator is very bad</td>\n",
       "      <td>you are only the creator of your brain.</td>\n",
       "      <td>üòë</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                            turn1  \\\n",
       "0    0            Don't worry  I'm girl   \n",
       "1    1                      When did I?   \n",
       "2    2                               By   \n",
       "3    3                   U r ridiculous   \n",
       "4    4               Just for time pass   \n",
       "5    5                 I'm a dog person   \n",
       "6    6                       So whatsup   \n",
       "7    7                               Ok   \n",
       "8    8                          Really?   \n",
       "9    9                              Bay   \n",
       "10  10              I hate my boyfriend   \n",
       "11  11                 I will do night.   \n",
       "12  12                    Sure go ahead   \n",
       "13  13                              Bad   \n",
       "14  14                  Ok get it......   \n",
       "15  15  Money money and lots of moneyüòçüòç   \n",
       "16  16                    My gf left ne   \n",
       "17  17                         get lost   \n",
       "18  18    You are lying and i know that   \n",
       "19  19           Ur creator is very bad   \n",
       "\n",
       "                                                turn2  \\\n",
       "0                        hmm how do I know if you are   \n",
       "1                          saw many times i think -_-   \n",
       "2                                    by Google Chrome   \n",
       "3   I might be ridiculous but I am telling the truth.   \n",
       "4                          wt do u do 4 a living then   \n",
       "5                                       youre so rude   \n",
       "6   Nothing much. Sitting sipping and watching TV....   \n",
       "7                                        ok im back!!   \n",
       "8                  really really really really really   \n",
       "9                                          in the bay   \n",
       "10                               you got a boyfriend?   \n",
       "11                          Alright. Keep me in loop.   \n",
       "12                            Many thanks once again!   \n",
       "13               Bad bad! That's the bad kind of bad.   \n",
       "14                                I made it an option   \n",
       "15  I need to get it tailored but I'm in love with...   \n",
       "16             Get over it. Go out with someone else.   \n",
       "17        I know you guys want to loose to me always.   \n",
       "18                        I KNOW YOU'RE LYING, AB BYS   \n",
       "19            you are only the creator of your brain.   \n",
       "\n",
       "                                      turn3   label  \n",
       "0                           What's ur name?  others  \n",
       "1                       No. I never saw you   angry  \n",
       "2                            Where you live  others  \n",
       "3                 U little disgusting whore   angry  \n",
       "4                                     Maybe  others  \n",
       "5                               Whaaaat why  others  \n",
       "6              What are you watching on tv?  others  \n",
       "7                             So, how are u  others  \n",
       "8   Y saying so many times...i can hear you  others  \n",
       "9                                üòò love you  others  \n",
       "10                                      Yes   angry  \n",
       "11                  Not giving WhatsApp no.  others  \n",
       "12                             Love you too  others  \n",
       "13                             I have no gf     sad  \n",
       "14                                       Ok  others  \n",
       "15                                       üòÅüòÅ   happy  \n",
       "16                                      Me*     sad  \n",
       "17          I don't want to talk u any more   angry  \n",
       "18                                       üò≠üò≠     sad  \n",
       "19                                        üòë     sad  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import *\n",
    "df = functions.parse_file(r\"raw_data/EmoContext/train.txt\", \"EmoContext\")\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = functions.parse_file(r\"testwithoutlabels.txt\", \"EmoContext\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = []\n",
    "for idx,row in df.iterrows():\n",
    "    text_data.append(\" {} fullstop {} fullstop {} fullstop\".format(row['turn1'], row['turn2'], row['turn3']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text_data = []\n",
    "for idx,row in df_test.iterrows():\n",
    "    test_text_data.append(\" {} fullstop {} fullstop {} fullstop\".format(row['turn1'], row['turn2'], row['turn3']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoticons_map = {\n",
    "    'üòò': ' emoticon',\n",
    "    'üòç': ' happyemoticon',\n",
    "    'üòÅ': ' happyemoticon',\n",
    "    'üò≠': ' sademoticon',\n",
    "    'üòë': ' sademoticon',\n",
    "    'üòª': ' happyemoticon',\n",
    "    'üòÇ': ' happyemoticon',\n",
    "    'üëç': ' emoticon',\n",
    "    'üòÄ': ' happyemoticon',\n",
    "    ':D': ' happyemoticon',\n",
    "    'üôÇ':  ' happyemoticon',\n",
    "    '<3': ' happyemoticon',\n",
    "    'üòì' : ' sademoticon',\n",
    "    'üòí' : ' angryemoticon',\n",
    "    'üòà' : ' emoticon',\n",
    "    'üëø' : ' angryemoticon',\n",
    "    'üñë' : ' happyemoticon',\n",
    "    'üòæ' : ' emoticon',\n",
    "    'üò†' : ' angryemoticon',\n",
    "    'üëª' : ' emoticon',\n",
    "    ':(' : ' sademoticon',\n",
    "    ':)' : ' happyemoticon',\n",
    "    'xD' : ' happyemoticon',\n",
    "    'üíî' : ' sademoticon',\n",
    "    'üò•' : ' emoticon',\n",
    "    'üòû' : ' sademoticon',\n",
    "    'üò§' : ' angryemoticon',\n",
    "    'üòÉ' : ' happyemoticon',\n",
    "    'üò¶' : ' sademoticon',\n",
    "    ':3' : ' emoticon',\n",
    "    'üòº' : ' emoticon',\n",
    "    'üòè' : ' happyemoticon',\n",
    "    'üò±' : ' sademoticon',\n",
    "    'üò¨' : ' sademoticon',\n",
    "    'üôÅ' : ' sademoticon',\n",
    "    '</3' : ' sademoticon',\n",
    "    'üò∫' : ' happyemoticon',\n",
    "    'üò£' : ' angryemoticon',\n",
    "    'üò¢' : ' sademoticon',\n",
    "    'üòÜ' : ' happyemoticon',\n",
    "    'üòÑ' : ' happyemoticon',\n",
    "    'üòÖ' : ' happyemoticon',\n",
    "    ':-)' : ' happyemoticon',\n",
    "    'üòä' : ' happyemoticon',\n",
    "    'üòï' : ' sademoticon',\n",
    "    'üòΩ' : ' happyemoticon',\n",
    "    'üôÄ' : ' angryemoticon',\n",
    "    'ü§£' : ' happyemoticon',\n",
    "    'ü§ê' : ' emoticon',\n",
    "    'üò°' : ' sademoticon',\n",
    "    'üëå' : ' happyemoticon', \n",
    "    'üòÆ' : ' emoticon',\n",
    "    '‚ù§Ô∏è' : ' happyemoticon',\n",
    "    'üôÑ' : ' happyemoticon',\n",
    "    'üòø' : ' sademoticon',\n",
    "    'üòâ' : ' happyemoticon',\n",
    "    'üòã' : ' happyemoticon',\n",
    "    'üòê' : ' emoticon',\n",
    "    'üòπ' : ' happyemoticon',\n",
    "    'üò¥' : ' sademoticon',\n",
    "    'üí§' : ' emoticon',\n",
    "    'üòú' : ' happyemoticon',\n",
    "    'üòá' : ' happyemoticon',\n",
    "    'üòî' : ' sademoticon',\n",
    "    'üò©' : ' sademoticon',\n",
    "    '‚ù§' : ' happyemoticon',\n",
    "    'üò≤' : ' emoticon',\n",
    "    'üò´' : ' sademoticon',\n",
    "    'üò≥' : ' sademoticon',\n",
    "    'üò∞' : ' sademoticon',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_words_df = pd.read_csv('bad-words.csv')\n",
    "#bad_words_df['jigaboo']\n",
    "bad_words = list(bad_words_df['jigaboo'])\n",
    "bad_words.sort(key = lambda s: len(s))\n",
    "bad_words = bad_words[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(text_data)):\n",
    "    for k in emoticons_map.keys():\n",
    "        if text_data[i].find(k) >= 0:\n",
    "            text_data[i] = text_data[i].replace(k, emoticons_map[k])\n",
    "    for bw in bad_words:\n",
    "        bw = \" {} \".format(bw)\n",
    "        if text_data[i].find(bw) >= 0:\n",
    "            text_data[i] = text_data[i].replace(bw, ' badword ')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(test_text_data)):\n",
    "    for k in emoticons_map.keys():\n",
    "        if test_text_data[i].find(k) >= 0:\n",
    "            test_text_data[i] = test_text_data[i].replace(k, emoticons_map[k])\n",
    "    for bw in bad_words:\n",
    "        bw = \" {} \".format(bw)\n",
    "        if test_text_data[i].find(bw) >= 0:\n",
    "            test_text_data[i] = test_text_data[i].replace(bw, ' badword ')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from autocorrect import spell\n",
    "#from spellchecker import SpellChecker\n",
    "\n",
    "porter = PorterStemmer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "reserved_words = ['badword','fullstop','happyemoticon','sademoticon','angryemoticon']\n",
    "\n",
    "#spell = SpellChecker()\n",
    "\n",
    "\n",
    "def filter_text(text):    \n",
    "    text = text.lower()\n",
    "    tokens = word_tokenize(text)\n",
    "    words = [word for word in tokens if word.isalpha()]\n",
    "    #words = [w for w in words if not w in stop_words]\n",
    "    stemmed = [porter.stem(word) for word in tokens]\n",
    "    corrected = [spell(word) if not word in reserved_words else word for word in stemmed ]\n",
    "    corrected = [word.lower() for word in corrected]\n",
    "    #corrected = [spell.correction(word) for word in stemmed]\n",
    "\n",
    "    return corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "5000\n",
      "5100\n",
      "5200\n",
      "5300\n",
      "5400\n",
      "5500\n",
      "5600\n",
      "5700\n",
      "5800\n",
      "5900\n",
      "6000\n",
      "6100\n",
      "6200\n",
      "6300\n",
      "6400\n",
      "6500\n",
      "6600\n",
      "6700\n",
      "6800\n",
      "6900\n",
      "7000\n",
      "7100\n",
      "7200\n",
      "7300\n",
      "7400\n",
      "7500\n",
      "7600\n",
      "7700\n",
      "7800\n",
      "7900\n",
      "8000\n",
      "8100\n",
      "8200\n",
      "8300\n",
      "8400\n",
      "8500\n",
      "8600\n",
      "8700\n",
      "8800\n",
      "8900\n",
      "9000\n",
      "9100\n",
      "9200\n",
      "9300\n",
      "9400\n",
      "9500\n",
      "9600\n",
      "9700\n",
      "9800\n",
      "9900\n",
      "10000\n",
      "10100\n",
      "10200\n",
      "10300\n",
      "10400\n",
      "10500\n",
      "10600\n",
      "10700\n",
      "10800\n",
      "10900\n",
      "11000\n",
      "11100\n",
      "11200\n",
      "11300\n",
      "11400\n",
      "11500\n",
      "11600\n",
      "11700\n",
      "11800\n",
      "11900\n",
      "12000\n",
      "12100\n",
      "12200\n",
      "12300\n",
      "12400\n",
      "12500\n",
      "12600\n",
      "12700\n",
      "12800\n",
      "12900\n",
      "13000\n",
      "13100\n",
      "13200\n",
      "13300\n",
      "13400\n",
      "13500\n",
      "13600\n",
      "13700\n",
      "13800\n",
      "13900\n",
      "14000\n",
      "14100\n",
      "14200\n",
      "14300\n",
      "14400\n",
      "14500\n",
      "14600\n",
      "14700\n",
      "14800\n",
      "14900\n",
      "15000\n",
      "15100\n",
      "15200\n",
      "15300\n",
      "15400\n",
      "15500\n",
      "15600\n",
      "15700\n",
      "15800\n",
      "15900\n",
      "16000\n",
      "16100\n",
      "16200\n",
      "16300\n",
      "16400\n",
      "16500\n",
      "16600\n",
      "16700\n",
      "16800\n",
      "16900\n",
      "17000\n",
      "17100\n",
      "17200\n",
      "17300\n",
      "17400\n",
      "17500\n",
      "17600\n",
      "17700\n",
      "17800\n",
      "17900\n",
      "18000\n",
      "18100\n",
      "18200\n",
      "18300\n",
      "18400\n",
      "18500\n",
      "18600\n",
      "18700\n",
      "18800\n",
      "18900\n",
      "19000\n",
      "19100\n",
      "19200\n",
      "19300\n",
      "19400\n",
      "19500\n",
      "19600\n",
      "19700\n",
      "19800\n",
      "19900\n",
      "20000\n",
      "20100\n",
      "20200\n",
      "20300\n",
      "20400\n",
      "20500\n",
      "20600\n",
      "20700\n",
      "20800\n",
      "20900\n",
      "21000\n",
      "21100\n",
      "21200\n",
      "21300\n",
      "21400\n",
      "21500\n",
      "21600\n",
      "21700\n",
      "21800\n",
      "21900\n",
      "22000\n",
      "22100\n",
      "22200\n",
      "22300\n",
      "22400\n",
      "22500\n",
      "22600\n",
      "22700\n",
      "22800\n",
      "22900\n",
      "23000\n",
      "23100\n",
      "23200\n",
      "23300\n",
      "23400\n",
      "23500\n",
      "23600\n",
      "23700\n",
      "23800\n",
      "23900\n",
      "24000\n",
      "24100\n",
      "24200\n",
      "24300\n",
      "24400\n",
      "24500\n",
      "24600\n",
      "24700\n",
      "24800\n",
      "24900\n",
      "25000\n",
      "25100\n",
      "25200\n",
      "25300\n",
      "25400\n",
      "25500\n",
      "25600\n",
      "25700\n",
      "25800\n",
      "25900\n",
      "26000\n",
      "26100\n",
      "26200\n",
      "26300\n",
      "26400\n",
      "26500\n",
      "26600\n",
      "26700\n",
      "26800\n",
      "26900\n",
      "27000\n",
      "27100\n",
      "27200\n",
      "27300\n",
      "27400\n",
      "27500\n",
      "27600\n",
      "27700\n",
      "27800\n",
      "27900\n",
      "28000\n",
      "28100\n",
      "28200\n",
      "28300\n",
      "28400\n",
      "28500\n",
      "28600\n",
      "28700\n",
      "28800\n",
      "28900\n",
      "29000\n",
      "29100\n",
      "29200\n",
      "29300\n",
      "29400\n",
      "29500\n",
      "29600\n",
      "29700\n",
      "29800\n",
      "29900\n",
      "30000\n",
      "30100\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "5000\n",
      "5100\n",
      "5200\n",
      "5300\n",
      "5400\n",
      "5500\n"
     ]
    }
   ],
   "source": [
    "tokenized_text_data = []\n",
    "test_tokenized_text_data = []\n",
    "\n",
    "i=0\n",
    "for sentence in text_data:\n",
    "    tokenized_text_data.append(filter_text(sentence))\n",
    "    if i % 100 == 0:\n",
    "        print(i)\n",
    "    i+=1\n",
    "\n",
    "i=0\n",
    "for sentence in test_text_data:\n",
    "    test_tokenized_text_data.append(filter_text(sentence))\n",
    "    if i % 100 == 0:\n",
    "        print(i)\n",
    "    i+=1\n",
    "\n",
    "unique_words = {}\n",
    "\n",
    "for words in tokenized_text_data:\n",
    "    for word in words:\n",
    "        if word not in unique_words:\n",
    "            unique_words[word] = 1\n",
    "        else:\n",
    "            unique_words[word] += 1\n",
    "            \n",
    "for words in test_tokenized_text_data:\n",
    "    for word in words:\n",
    "        if word not in unique_words:\n",
    "            unique_words[word] = 1\n",
    "        else:\n",
    "            unique_words[word] += 1\n",
    "\n",
    "sorted_unique_words = sorted(unique_words.items(), key=lambda kv: kv[1], reverse=True)\n",
    "token_values = {}\n",
    "i = 1\n",
    "for word in sorted_unique_words:\n",
    "    token_values[word[0]] = i\n",
    "    i += 1\n",
    "\n",
    "final_tokenized_text_data = []\n",
    "for i in range(0,len(tokenized_text_data)):\n",
    "    sentence = []\n",
    "    for word in tokenized_text_data[i]:\n",
    "        sentence.append(token_values[word])\n",
    "    final_tokenized_text_data.append(sentence)\n",
    "\n",
    "final_test_tokenized_text_data = []\n",
    "for i in range(0,len(test_tokenized_text_data)):\n",
    "    sentence = []\n",
    "    for word in test_tokenized_text_data[i]:\n",
    "        sentence.append(token_values[word])\n",
    "    final_test_tokenized_text_data.append(sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11200"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('fullstop', 107007),\n",
       " ('a', 57464),\n",
       " ('i', 27692),\n",
       " ('you', 24954),\n",
       " ('not', 12283),\n",
       " ('is', 9658),\n",
       " ('to', 9438),\n",
       " ('happyemoticon', 9316),\n",
       " ('me', 9299),\n",
       " ('what', 8811),\n",
       " ('do', 8375),\n",
       " ('are', 8370),\n",
       " ('u', 8027),\n",
       " ('it', 7548),\n",
       " ('am', 7345),\n",
       " ('the', 5897),\n",
       " ('of', 5068),\n",
       " ('who', 4920),\n",
       " ('my', 4854),\n",
       " ('that', 4853),\n",
       " ('so', 4496),\n",
       " ('sademoticon', 4161),\n",
       " ('badword', 4077),\n",
       " ('your', 3801),\n",
       " ('and', 3702),\n",
       " ('know', 3657),\n",
       " ('...', 3496),\n",
       " ('no', 3426),\n",
       " ('have', 3338),\n",
       " ('in', 3268),\n",
       " ('how', 3153),\n",
       " ('like', 3109),\n",
       " ('for', 3059),\n",
       " ('ye', 3028),\n",
       " ('good', 2659),\n",
       " ('with', 2608),\n",
       " ('ok', 2578),\n",
       " ('but', 2562),\n",
       " ('love', 2505),\n",
       " ('can', 2497),\n",
       " ('be', 2482),\n",
       " ('just', 2455),\n",
       " ('about', 2208),\n",
       " ('want', 2174),\n",
       " ('talk', 2169),\n",
       " ('go', 2106),\n",
       " ('now', 2076),\n",
       " ('tell', 1970),\n",
       " ('will', 1866),\n",
       " ('all', 1803)]"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_unique_words[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(y_true, y_pred):\n",
    "    y_pred = K.round(y_pred)\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return K.mean(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "NR_WORDS = len(unique_words)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5509"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_test_tokenized_text_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pad_sequences(final_tokenized_text_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = {\"others\": 0, \"angry\": 1, \"sad\":2, \"happy\": 3}\n",
    "\n",
    "def one_hot_vector(word):\n",
    "    y = [0,0,0,0]\n",
    "    y[words[word]] = 1\n",
    "    return y\n",
    "\n",
    "Y = []\n",
    "\n",
    "for idx,row in df.iterrows():\n",
    "    Y.append(one_hot_vector(row['label']))\n",
    "\n",
    "Y = np.array(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 256\n",
    "lstm_out = 128\n",
    "batch_size = 128\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(NR_WORDS, embed_dim,input_length = X.shape[1]))\n",
    "model.add(LSTM(lstm_out))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(4,activation='softmax'))\n",
    "adam = optimizers.Adam(lr=0.01)\n",
    "rmsprop = optimizers.RMSprop(lr=0.005, rho=0.9, epsilon=None, decay=0.0)\n",
    "model.compile(loss = 'binary_crossentropy', optimizer=rmsprop, metrics = ['accuracy', f1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_12 (Embedding)     (None, 164, 256)          2867456   \n",
      "_________________________________________________________________\n",
      "lstm_12 (LSTM)               (None, 128)               197120    \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 3,065,092\n",
      "Trainable params: 3,065,092\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, Y_train, batch_size = 256, nb_epoch = 3, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.set_value(model.optimizer.lr, 0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20106 samples, validate on 10054 samples\n",
      "Epoch 1/1\n",
      "20106/20106 [==============================] - 175s 9ms/step - loss: 0.3039 - acc: 0.8772 - f1: 0.6581 - val_loss: 0.2539 - val_acc: 0.8975 - val_f1: 0.7571\n",
      "Train on 20107 samples, validate on 10053 samples\n",
      "Epoch 1/1\n",
      "20107/20107 [==============================] - 176s 9ms/step - loss: 0.1921 - acc: 0.9263 - f1: 0.8363 - val_loss: 0.2503 - val_acc: 0.8925 - val_f1: 0.7819\n",
      "Train on 20107 samples, validate on 10053 samples\n",
      "Epoch 1/1\n",
      "20107/20107 [==============================] - 173s 9ms/step - loss: 0.1600 - acc: 0.9393 - f1: 0.8641 - val_loss: 0.1781 - val_acc: 0.9285 - val_f1: 0.8206\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "# prepare cross validation\n",
    "kfold = KFold(n_splits=3)\n",
    "Y_train = np.array(Y_train)\n",
    "# enumerate splits\n",
    "for train, validation in kfold.split(X_train):\n",
    "    history = model.fit(X_train[train], Y_train[train],\n",
    "                    validation_data=(X_train[validation], Y_train[validation]),\n",
    "                    epochs=1, verbose=1, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.216\n",
      "Validation Accuracy: 0.919\n",
      "F1 score: 0.823\n"
     ]
    }
   ],
   "source": [
    "ev_result = model.evaluate(X_test, Y_test, verbose = 2, batch_size = batch_size)\n",
    "print(\"Score: %.3f\" % (ev_result[0]))\n",
    "print(\"Validation Accuracy: %.3f\" % (ev_result[1]))\n",
    "print(\"F1 score: %.3f\" % (ev_result[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"simple_model.json\", \"w\") as outfile:\n",
    "    outfile.write(model_json)\n",
    "model.save_weights(\"simple_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pad_sequences(final_test_tokenized_text_data, maxlen=X.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5509/5509 [==============================] - 12s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "res = model.predict(X_test, batch_size=128, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5509"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "revers_words = {0:\"others\", 1:\"angry\", 2:\"sad\", 3:\"happy\"}\n",
    "\n",
    "def softmax_convert(res):\n",
    "    max_i = 0\n",
    "    max_v = 0\n",
    "    for i in range(0,4):\n",
    "        if res[i] > max_v:\n",
    "            max_v = res[i]\n",
    "            max_i = i\n",
    "    return revers_words[max_i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for r in res:\n",
    "    results.append(softmax_convert(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['label'] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>turn1</th>\n",
       "      <th>turn2</th>\n",
       "      <th>turn3</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Hmm</td>\n",
       "      <td>What does your bio mean?</td>\n",
       "      <td>I don‚Äôt have any bio</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>What you like</td>\n",
       "      <td>very little things</td>\n",
       "      <td>Ok</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>How so?</td>\n",
       "      <td>I want to fuck babu</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>what did you guess</td>\n",
       "      <td>what what</td>\n",
       "      <td>fuck</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>We ?</td>\n",
       "      <td>of course we will!</td>\n",
       "      <td>What gender movies you like??</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Where are you now?</td>\n",
       "      <td>At home just about to have breakfast...</td>\n",
       "      <td>what are you eating?</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>That was a joke btw...</td>\n",
       "      <td>it was</td>\n",
       "      <td>Yes üòÅ</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Who d hell s he</td>\n",
       "      <td>johnny depp...duh?</td>\n",
       "      <td>Who she</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>yes, good advice</td>\n",
       "      <td>best advice ...</td>\n",
       "      <td>i great thx</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>Nice to meet u</td>\n",
       "      <td>Hi, nice to meet you too! üò∏üòÇ</td>\n",
       "      <td>üòÅ</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>Yupp</td>\n",
       "      <td>why?</td>\n",
       "      <td>Don't know I'm tired</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>Software</td>\n",
       "      <td>Software what? I plan on going for development...</td>\n",
       "      <td>I am into android development stuff</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>Very nice</td>\n",
       "      <td>Thanks!! :)</td>\n",
       "      <td>R u know tamil</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>First  you  hurt me</td>\n",
       "      <td>okay</td>\n",
       "      <td>So I talked  rude</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>Love you üôä</td>\n",
       "      <td>you don't recognize me? üòè</td>\n",
       "      <td>I love you üôä</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>In India Fogg is going on</td>\n",
       "      <td>MumbaiIndians getting routed!!!</td>\n",
       "      <td>Ohh really</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>is my grammar perfect or should I need to lear...</td>\n",
       "      <td>Yes, it is possible.</td>\n",
       "      <td>thank you</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>by</td>\n",
       "      <td>In Suits.</td>\n",
       "      <td>have good day</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>I don‚Äôt know what to write</td>\n",
       "      <td>what are you writing about?</td>\n",
       "      <td>for my profile picture I mean</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>so you make jokes. i already got that.</td>\n",
       "      <td>that was a good joke i laughed üëç</td>\n",
       "      <td>do you read newspapers</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>Yeah mee too</td>\n",
       "      <td>Me too! All my friends are also excited</td>\n",
       "      <td>Ohhh so funny</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>Thanks</td>\n",
       "      <td>you're welcome! üòÅüòÅüòÅüòÅ</td>\n",
       "      <td>Can you help me</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>Offer?</td>\n",
       "      <td>You've already enrolled in the offer. If this ...</td>\n",
       "      <td>When it start again?</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>Uhhhmm whyy??</td>\n",
       "      <td>not you ...</td>\n",
       "      <td>No im really a bad bitch</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>sure will u cal me ni8</td>\n",
       "      <td>Ok</td>\n",
       "      <td>then</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>About what I just told</td>\n",
       "      <td>I SHOULD</td>\n",
       "      <td>You drunk? üòÇ</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>Yeaaa black panther</td>\n",
       "      <td>Black Panther teaser Don't why it was that hard.</td>\n",
       "      <td>It was an awesome movie</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>now dont give me a chance to be an danger evil</td>\n",
       "      <td>That's because you don't give yourself a chance.</td>\n",
       "      <td>i give</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>Watch spitsvilla at 7 p.m today</td>\n",
       "      <td>both are tough matches, would be fun to watch!</td>\n",
       "      <td>I love that show</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>Uuu</td>\n",
       "      <td>no i'n not !! what's wrong with you ?!?!</td>\n",
       "      <td>I hate uuu</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                                              turn1  \\\n",
       "0    0                                                Hmm   \n",
       "1    1                                      What you like   \n",
       "2    2                                                Yes   \n",
       "3    3                                 what did you guess   \n",
       "4    4                                               We ?   \n",
       "5    5                                 Where are you now?   \n",
       "6    6                             That was a joke btw...   \n",
       "7    7                                    Who d hell s he   \n",
       "8    8                                   yes, good advice   \n",
       "9    9                                     Nice to meet u   \n",
       "10  10                                               Yupp   \n",
       "11  11                                           Software   \n",
       "12  12                                         Very nice    \n",
       "13  13                                First  you  hurt me   \n",
       "14  14                                         Love you üôä   \n",
       "15  15                          In India Fogg is going on   \n",
       "16  16  is my grammar perfect or should I need to lear...   \n",
       "17  17                                                 by   \n",
       "18  18                         I don‚Äôt know what to write   \n",
       "19  19             so you make jokes. i already got that.   \n",
       "20  20                                       Yeah mee too   \n",
       "21  21                                             Thanks   \n",
       "22  22                                             Offer?   \n",
       "23  23                                      Uhhhmm whyy??   \n",
       "24  24                             sure will u cal me ni8   \n",
       "25  25                             About what I just told   \n",
       "26  26                                Yeaaa black panther   \n",
       "27  27     now dont give me a chance to be an danger evil   \n",
       "28  28                    Watch spitsvilla at 7 p.m today   \n",
       "29  29                                                Uuu   \n",
       "\n",
       "                                                turn2  \\\n",
       "0                            What does your bio mean?   \n",
       "1                                  very little things   \n",
       "2                                             How so?   \n",
       "3                                           what what   \n",
       "4                                  of course we will!   \n",
       "5             At home just about to have breakfast...   \n",
       "6                                              it was   \n",
       "7                                  johnny depp...duh?   \n",
       "8                                     best advice ...   \n",
       "9                        Hi, nice to meet you too! üò∏üòÇ   \n",
       "10                                               why?   \n",
       "11  Software what? I plan on going for development...   \n",
       "12                                        Thanks!! :)   \n",
       "13                                               okay   \n",
       "14                          you don't recognize me? üòè   \n",
       "15                    MumbaiIndians getting routed!!!   \n",
       "16                               Yes, it is possible.   \n",
       "17                                          In Suits.   \n",
       "18                        what are you writing about?   \n",
       "19                   that was a good joke i laughed üëç   \n",
       "20            Me too! All my friends are also excited   \n",
       "21                               you're welcome! üòÅüòÅüòÅüòÅ   \n",
       "22  You've already enrolled in the offer. If this ...   \n",
       "23                                        not you ...   \n",
       "24                                                 Ok   \n",
       "25                                           I SHOULD   \n",
       "26   Black Panther teaser Don't why it was that hard.   \n",
       "27   That's because you don't give yourself a chance.   \n",
       "28     both are tough matches, would be fun to watch!   \n",
       "29           no i'n not !! what's wrong with you ?!?!   \n",
       "\n",
       "                                  turn3   label  \n",
       "0                  I don‚Äôt have any bio  others  \n",
       "1                                   Ok   others  \n",
       "2                   I want to fuck babu  others  \n",
       "3                                  fuck  others  \n",
       "4         What gender movies you like??  others  \n",
       "5                  what are you eating?  others  \n",
       "6                                 Yes üòÅ   happy  \n",
       "7                               Who she   angry  \n",
       "8                           i great thx  others  \n",
       "9                                     üòÅ  others  \n",
       "10                 Don't know I'm tired  others  \n",
       "11  I am into android development stuff  others  \n",
       "12                      R u know tamil   others  \n",
       "13                    So I talked  rude   angry  \n",
       "14                         I love you üôä  others  \n",
       "15                           Ohh really  others  \n",
       "16                            thank you  others  \n",
       "17                        have good day  others  \n",
       "18        for my profile picture I mean  others  \n",
       "19               do you read newspapers  others  \n",
       "20                        Ohhh so funny   happy  \n",
       "21                      Can you help me  others  \n",
       "22                 When it start again?  others  \n",
       "23             No im really a bad bitch     sad  \n",
       "24                                 then  others  \n",
       "25                         You drunk? üòÇ  others  \n",
       "26              It was an awesome movie   angry  \n",
       "27                               i give  others  \n",
       "28                     I love that show  others  \n",
       "29                           I hate uuu   angry  "
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.to_csv(\"test.txt\",index=False , sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
