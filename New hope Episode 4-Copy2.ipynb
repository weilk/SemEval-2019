{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from keras.layers import Dropout\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential,clone_model\n",
    "from keras.layers import Dense, Embedding, LSTM\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras import optimizers\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import tensorflow as tf\n",
    "\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(y_true, y_pred):\n",
    "    y_pred = K.round(y_pred)\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return K.mean(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>turn1</th>\n",
       "      <th>turn2</th>\n",
       "      <th>turn3</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Don't worry  I'm girl</td>\n",
       "      <td>hmm how do I know if you are</td>\n",
       "      <td>What's ur name?</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>When did I?</td>\n",
       "      <td>saw many times i think -_-</td>\n",
       "      <td>No. I never saw you</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>By</td>\n",
       "      <td>by Google Chrome</td>\n",
       "      <td>Where you live</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>U r ridiculous</td>\n",
       "      <td>I might be ridiculous but I am telling the truth.</td>\n",
       "      <td>U little disgusting whore</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Just for time pass</td>\n",
       "      <td>wt do u do 4 a living then</td>\n",
       "      <td>Maybe</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id                  turn1  \\\n",
       "0  0  Don't worry  I'm girl   \n",
       "1  1            When did I?   \n",
       "2  2                     By   \n",
       "3  3         U r ridiculous   \n",
       "4  4     Just for time pass   \n",
       "\n",
       "                                               turn2  \\\n",
       "0                       hmm how do I know if you are   \n",
       "1                         saw many times i think -_-   \n",
       "2                                   by Google Chrome   \n",
       "3  I might be ridiculous but I am telling the truth.   \n",
       "4                         wt do u do 4 a living then   \n",
       "\n",
       "                       turn3   label  \n",
       "0            What's ur name?  others  \n",
       "1        No. I never saw you   angry  \n",
       "2             Where you live  others  \n",
       "3  U little disgusting whore   angry  \n",
       "4                      Maybe  others  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import *\n",
    "df = functions.parse_file(r\"raw_data/EmoContext/train.txt\", \"EmoContext\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = []\n",
    "for idx,row in df.iterrows():\n",
    "    text_data.append(\"{}. {}. {}.\".format(row['turn1'], row['turn2'], row['turn3']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "NR_WORDS = 5000\n",
    "MAX_PROP_LENGTH = 200\n",
    "tokenizer = Tokenizer(num_words=NR_WORDS, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
    "                                   lower=True,split=' ')\n",
    "\n",
    "tokenizer.fit_on_texts(text_data)\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(text_data)\n",
    "X_train = pad_sequences(X_train, maxlen = MAX_PROP_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_vector(word,label=None):\n",
    "    words = {\"others\": 0, \"angry\": 1, \"sad\":2, \"happy\": 3}\n",
    "    if label == None:\n",
    "        y = [0,0,0,0]\n",
    "        y[words[word]] = 1\n",
    "        return y\n",
    "    if label == word:\n",
    "        return [1,0]\n",
    "    return [0,1]\n",
    "\n",
    "Y_train_others = []\n",
    "Y_train_angry = []\n",
    "Y_train_sad = []\n",
    "Y_train_happy = []\n",
    "\n",
    "for idx,row in df.iterrows():\n",
    "    Y_train_others.append(one_hot_vector(row['label'],\"others\"))\n",
    "    Y_train_angry.append(one_hot_vector(row['label'],\"angry\"))\n",
    "    Y_train_sad.append(one_hot_vector(row['label'],\"sad\"))\n",
    "    Y_train_happy.append(one_hot_vector(row['label'],\"happy\"))\n",
    "\n",
    "Y_train_others = np.array(Y_train_others)\n",
    "Y_train_angry = np.array(Y_train_angry)\n",
    "Y_train_sad = np.array(Y_train_sad)\n",
    "Y_train_happy = np.array(Y_train_happy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>turn1</th>\n",
       "      <th>turn2</th>\n",
       "      <th>turn3</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Then dont ask me</td>\n",
       "      <td>YOURE A GUY NOT AS IF YOU WOULD UNDERSTAND</td>\n",
       "      <td>IM NOT A GUY FUCK OFF</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Mixed things  such as??</td>\n",
       "      <td>the things you do.</td>\n",
       "      <td>Have you seen minions??</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Today I'm very happy</td>\n",
       "      <td>and I'm happy for you ❤</td>\n",
       "      <td>I will be marry</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Woah bring me some</td>\n",
       "      <td>left it there oops</td>\n",
       "      <td>Brb</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>it is thooooo</td>\n",
       "      <td>I said soon master.</td>\n",
       "      <td>he is pressuring me</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id                    turn1                                       turn2  \\\n",
       "0  0         Then dont ask me  YOURE A GUY NOT AS IF YOU WOULD UNDERSTAND   \n",
       "1  1  Mixed things  such as??                          the things you do.   \n",
       "2  2     Today I'm very happy                     and I'm happy for you ❤   \n",
       "3  3       Woah bring me some                          left it there oops   \n",
       "4  4            it is thooooo                         I said soon master.   \n",
       "\n",
       "                     turn3   label  \n",
       "0    IM NOT A GUY FUCK OFF   angry  \n",
       "1  Have you seen minions??  others  \n",
       "2          I will be marry   happy  \n",
       "3                      Brb  others  \n",
       "4      he is pressuring me  others  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = functions.parse_file(r\"raw_data/EmoContext/devwithlabels.txt\", \"EmoContext\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = []\n",
    "for idx,row in df.iterrows():\n",
    "    text_data.append(\"{}. {}. {}.\".format(row['turn1'], row['turn2'], row['turn3']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=NR_WORDS, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
    "                                   lower=True,split=' ')\n",
    "\n",
    "tokenizer.fit_on_texts(text_data)\n",
    "\n",
    "X_test = tokenizer.texts_to_sequences(text_data)\n",
    "X_test = pad_sequences(X_test, maxlen = MAX_PROP_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_vector(word,label=None):\n",
    "    words = {\"others\": 0, \"angry\": 1, \"sad\":2, \"happy\": 3}\n",
    "    if label == None:\n",
    "        y = [0,0,0,0]\n",
    "        y[words[word]] = 1\n",
    "        return y\n",
    "    if label == word:\n",
    "        return [1,0]\n",
    "    return [0,1]\n",
    "\n",
    "Y_test_others = []\n",
    "Y_test_angry = []\n",
    "Y_test_sad = []\n",
    "Y_test_happy = []\n",
    "\n",
    "for idx,row in df.iterrows():\n",
    "    Y_test_others.append(one_hot_vector(row['label'],\"others\"))\n",
    "    Y_test_angry.append(one_hot_vector(row['label'],\"angry\"))\n",
    "    Y_test_sad.append(one_hot_vector(row['label'],\"sad\"))\n",
    "    Y_test_happy.append(one_hot_vector(row['label'],\"happy\"))\n",
    "\n",
    "Y_test_others = np.array(Y_test_others)\n",
    "Y_test_angry = np.array(Y_test_angry)\n",
    "Y_test_sad = np.array(Y_test_sad)\n",
    "Y_test_happy = np.array(Y_test_happy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 128\n",
    "lstm_out = 32\n",
    "batch_size = 64\n",
    "\n",
    "adam = optimizers.Adam(lr=0.01)\n",
    "rmsprop = optimizers.RMSprop(lr=0.005, rho=0.9, epsilon=None, decay=0.0)\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(NR_WORDS, embed_dim,input_length = X_train.shape[1]))\n",
    "model.add(LSTM(lstm_out,dropout=0.5))\n",
    "model.add(Dense(2,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 200, 128)          640000    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 32)                20608     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 660,674\n",
      "Trainable params: 660,674\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdcheck = ModelCheckpoint(\"trained_models/best_model_val_acc{val_acc:.4f}.h5\", monitor='val_f1', save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 30160 samples, validate on 2755 samples\n",
      "Epoch 1/5\n",
      "30160/30160 [==============================] - 69s 2ms/step - loss: 0.1947 - acc: 0.9297 - f1: 0.8670 - val_loss: 0.5677 - val_acc: 0.7891 - val_f1: 0.4789\n",
      "Epoch 2/5\n",
      "30160/30160 [==============================] - 67s 2ms/step - loss: 0.1478 - acc: 0.9469 - f1: 0.9069 - val_loss: 0.5565 - val_acc: 0.8087 - val_f1: 0.4881\n",
      "Epoch 3/5\n",
      "30160/30160 [==============================] - 67s 2ms/step - loss: 0.1342 - acc: 0.9521 - f1: 0.9159 - val_loss: 0.5016 - val_acc: 0.7953 - val_f1: 0.4825\n",
      "Epoch 4/5\n",
      "30160/30160 [==============================] - 68s 2ms/step - loss: 0.1265 - acc: 0.9544 - f1: 0.9194 - val_loss: 0.5352 - val_acc: 0.8145 - val_f1: 0.4819\n",
      "Epoch 5/5\n",
      "30160/30160 [==============================] - 68s 2ms/step - loss: 0.1189 - acc: 0.9578 - f1: 0.9261 - val_loss: 0.5655 - val_acc: 0.8167 - val_f1: 0.4815\n"
     ]
    }
   ],
   "source": [
    "Y_train_angry = np.array(Y_train_angry)\n",
    "\n",
    "model_angry = clone_model(model)\n",
    "model_angry.compile(loss = 'binary_crossentropy', optimizer=rmsprop, metrics = ['accuracy', f1])\n",
    "history = model_angry.fit(X_train, Y_train_angry,\n",
    "                    validation_data=(X_test, Y_test_angry),\n",
    "                    epochs=5, verbose=1, batch_size=batch_size,callbacks=[mdcheck])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 30160 samples, validate on 2755 samples\n",
      "Epoch 1/5\n",
      "30160/30160 [==============================] - 69s 2ms/step - loss: 0.2202 - acc: 0.9180 - f1: 0.8424 - val_loss: 0.3437 - val_acc: 0.8730 - val_f1: 0.4930\n",
      "Epoch 2/5\n",
      "30160/30160 [==============================] - 69s 2ms/step - loss: 0.1613 - acc: 0.9442 - f1: 0.9007 - val_loss: 0.3697 - val_acc: 0.8697 - val_f1: 0.5007\n",
      "Epoch 3/5\n",
      "30160/30160 [==============================] - 68s 2ms/step - loss: 0.1439 - acc: 0.9512 - f1: 0.9128 - val_loss: 0.3561 - val_acc: 0.8849 - val_f1: 0.4999\n",
      "Epoch 4/5\n",
      "30160/30160 [==============================] - 68s 2ms/step - loss: 0.1316 - acc: 0.9562 - f1: 0.9211 - val_loss: 0.3656 - val_acc: 0.8711 - val_f1: 0.4948\n",
      "Epoch 5/5\n",
      "30160/30160 [==============================] - 72s 2ms/step - loss: 0.1230 - acc: 0.9591 - f1: 0.9263 - val_loss: 0.3668 - val_acc: 0.8802 - val_f1: 0.4976\n"
     ]
    }
   ],
   "source": [
    "Y_train_sad = np.array(Y_train_sad)\n",
    "\n",
    "model_sad = clone_model(model)\n",
    "model_sad.compile(loss = 'binary_crossentropy', optimizer=rmsprop, metrics = ['accuracy', f1])\n",
    "history = model_sad.fit(X_train, Y_train_sad,\n",
    "                    validation_data=(X_test, Y_test_sad),\n",
    "                    epochs=5, verbose=1, batch_size=batch_size,callbacks=[mdcheck])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 30160 samples, validate on 2755 samples\n",
      "Epoch 1/5\n",
      "30160/30160 [==============================] - 71s 2ms/step - loss: 0.1775 - acc: 0.9357 - f1: 0.8451 - val_loss: 0.3141 - val_acc: 0.8922 - val_f1: 0.5202\n",
      "Epoch 2/5\n",
      "30160/30160 [==============================] - 70s 2ms/step - loss: 0.1325 - acc: 0.9538 - f1: 0.8974 - val_loss: 0.3471 - val_acc: 0.8704 - val_f1: 0.5188\n",
      "Epoch 3/5\n",
      "30160/30160 [==============================] - 69s 2ms/step - loss: 0.1179 - acc: 0.9580 - f1: 0.9064 - val_loss: 0.2997 - val_acc: 0.9056 - val_f1: 0.5422\n",
      "Epoch 4/5\n",
      "30160/30160 [==============================] - 71s 2ms/step - loss: 0.1105 - acc: 0.9605 - f1: 0.9123 - val_loss: 0.3028 - val_acc: 0.9013 - val_f1: 0.5253\n",
      "Epoch 5/5\n",
      "30160/30160 [==============================] - 67s 2ms/step - loss: 0.1035 - acc: 0.9642 - f1: 0.9209 - val_loss: 0.3461 - val_acc: 0.8915 - val_f1: 0.5324\n"
     ]
    }
   ],
   "source": [
    "Y_train_happy = np.array(Y_train_happy)\n",
    "\n",
    "model_happy = clone_model(model)\n",
    "model_happy.compile(loss = 'binary_crossentropy', optimizer=rmsprop, metrics = ['accuracy', f1])\n",
    "history = model_happy.fit(X_train, Y_train_happy,\n",
    "                    validation_data=(X_test, Y_test_happy),\n",
    "                    epochs=5, verbose=1, batch_size=batch_size,callbacks=[mdcheck])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 30160 samples, validate on 2755 samples\n",
      "Epoch 1/5\n",
      "30160/30160 [==============================] - 75s 2ms/step - loss: 0.3740 - acc: 0.8395 - f1: 0.8358 - val_loss: 0.9653 - val_acc: 0.5038 - val_f1: 0.4237\n",
      "Epoch 2/5\n",
      "30160/30160 [==============================] - 75s 2ms/step - loss: 0.3021 - acc: 0.8803 - f1: 0.8787 - val_loss: 1.1434 - val_acc: 0.5118 - val_f1: 0.4242\n",
      "Epoch 3/5\n",
      "30160/30160 [==============================] - 69s 2ms/step - loss: 0.2767 - acc: 0.8908 - f1: 0.8892 - val_loss: 1.0985 - val_acc: 0.5354 - val_f1: 0.4372\n",
      "Epoch 4/5\n",
      "30160/30160 [==============================] - 71s 2ms/step - loss: 0.2552 - acc: 0.9027 - f1: 0.9012 - val_loss: 1.3080 - val_acc: 0.5238 - val_f1: 0.4375\n",
      "Epoch 5/5\n",
      "30160/30160 [==============================] - 69s 2ms/step - loss: 0.2379 - acc: 0.9097 - f1: 0.9085 - val_loss: 1.0775 - val_acc: 0.5615 - val_f1: 0.4474\n"
     ]
    }
   ],
   "source": [
    "Y_train_others = np.array(Y_train_others)\n",
    "\n",
    "model_others = clone_model(model)\n",
    "model_others.compile(loss = 'binary_crossentropy', optimizer=rmsprop, metrics = ['accuracy', f1])\n",
    "history = model_others.fit(X_train, Y_train_others,\n",
    "                    validation_data=(X_test, Y_test_others),\n",
    "                    epochs=5, verbose=1, batch_size=batch_size,callbacks=[mdcheck])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"lstm_normal_model_others.json\", \"w\") as outfile:\n",
    "    outfile.write(model_json)\n",
    "model.save_weights(\"lstm_normal_12_epochs_cv_others.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"lstm_normal_model_angry.json\", \"w\") as outfile:\n",
    "    outfile.write(model_json)\n",
    "model.save_weights(\"lstm_normal_12_epochs_cv_angry.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"lstm_normal_model_sad.json\", \"w\") as outfile:\n",
    "    outfile.write(model_json)\n",
    "model.save_weights(\"lstm_normal_12_epochs_cv_sad.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"lstm_normal_model_happy.json\", \"w\") as outfile:\n",
    "    outfile.write(model_json)\n",
    "model.save_weights(\"lstm_normal_12_epochs_cv_happy.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36-test",
   "language": "python",
   "name": "py36-test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
