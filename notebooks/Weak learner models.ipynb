{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from keras.layers import Dropout\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential,clone_model\n",
    "from keras.layers import Dense, Embedding, LSTM\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras import optimizers\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import tensorflow as tf\n",
    "\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(y_true, y_pred):\n",
    "    y_pred = K.round(y_pred)\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return K.mean(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>turn1</th>\n",
       "      <th>turn2</th>\n",
       "      <th>turn3</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>dont worry ism girl</td>\n",
       "      <td>hmm how do i know if you are</td>\n",
       "      <td>whats ur name ?  ?</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>when did in  i?</td>\n",
       "      <td>saw many times i think   -_-</td>\n",
       "      <td>no . i never saw you  .</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>by</td>\n",
       "      <td>by google chrome</td>\n",
       "      <td>where you live</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>u r ridiculous</td>\n",
       "      <td>i might be ridiculous but i am telling the tru...</td>\n",
       "      <td>u little disgusting whore</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>just for time pass</td>\n",
       "      <td>wt do u do a a living then  4</td>\n",
       "      <td>maybe</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id                  turn1  \\\n",
       "0  0  dont worry ism girl     \n",
       "1  1        when did in  i?   \n",
       "2  2                   by     \n",
       "3  3       u r ridiculous     \n",
       "4  4   just for time pass     \n",
       "\n",
       "                                               turn2  \\\n",
       "0                     hmm how do i know if you are     \n",
       "1                       saw many times i think   -_-   \n",
       "2                                 by google chrome     \n",
       "3  i might be ridiculous but i am telling the tru...   \n",
       "4                     wt do u do a a living then  4    \n",
       "\n",
       "                         turn3   label  \n",
       "0           whats ur name ?  ?  others  \n",
       "1     no . i never saw you  .    angry  \n",
       "2             where you live    others  \n",
       "3  u little disgusting whore     angry  \n",
       "4                      maybe    others  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import *\n",
    "df = functions.parse_file(r\"raw_data/EmoContext/train2.txt\", \"EmoContext\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = []\n",
    "for idx,row in df.iterrows():\n",
    "    text_data.append(\"{}. {}. {}.\".format(row['turn1'], row['turn2'], row['turn3']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "NR_WORDS = 5000\n",
    "MAX_PROP_LENGTH = 100\n",
    "tokenizer = Tokenizer(num_words=NR_WORDS, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
    "                                   lower=True,split=' ')\n",
    "\n",
    "tokenizer.fit_on_texts(text_data)\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(text_data)\n",
    "X_train = pad_sequences(X_train, maxlen = MAX_PROP_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_vector(word,label=None):\n",
    "    words = {\"others\": 0, \"angry\": 1, \"sad\":2, \"happy\": 3}\n",
    "    if label == None:\n",
    "        y = [0,0,0,0]\n",
    "        y[words[word]] = 1\n",
    "        return y\n",
    "    if label == word:\n",
    "        return [1,0]\n",
    "    return [0,1]\n",
    "\n",
    "Y_train_others = []\n",
    "Y_train_angry = []\n",
    "Y_train_sad = []\n",
    "Y_train_happy = []\n",
    "\n",
    "for idx,row in df.iterrows():\n",
    "    Y_train_others.append(one_hot_vector(row['label'],\"others\"))\n",
    "    Y_train_angry.append(one_hot_vector(row['label'],\"angry\"))\n",
    "    Y_train_sad.append(one_hot_vector(row['label'],\"sad\"))\n",
    "    Y_train_happy.append(one_hot_vector(row['label'],\"happy\"))\n",
    "\n",
    "Y_train_others = np.array(Y_train_others)\n",
    "Y_train_angry = np.array(Y_train_angry)\n",
    "Y_train_sad = np.array(Y_train_sad)\n",
    "Y_train_happy = np.array(Y_train_happy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>turn1</th>\n",
       "      <th>turn2</th>\n",
       "      <th>turn3</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Then dont ask me</td>\n",
       "      <td>YOURE A GUY NOT AS IF YOU WOULD UNDERSTAND</td>\n",
       "      <td>IM NOT A GUY FUCK OFF</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Mixed things  such as??</td>\n",
       "      <td>the things you do.</td>\n",
       "      <td>Have you seen minions??</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Today I'm very happy</td>\n",
       "      <td>and I'm happy for you ‚ù§</td>\n",
       "      <td>I will be marry</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Woah bring me some</td>\n",
       "      <td>left it there oops</td>\n",
       "      <td>Brb</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>it is thooooo</td>\n",
       "      <td>I said soon master.</td>\n",
       "      <td>he is pressuring me</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id                    turn1                                       turn2  \\\n",
       "0  0         Then dont ask me  YOURE A GUY NOT AS IF YOU WOULD UNDERSTAND   \n",
       "1  1  Mixed things  such as??                          the things you do.   \n",
       "2  2     Today I'm very happy                     and I'm happy for you ‚ù§   \n",
       "3  3       Woah bring me some                          left it there oops   \n",
       "4  4            it is thooooo                         I said soon master.   \n",
       "\n",
       "                     turn3   label  \n",
       "0    IM NOT A GUY FUCK OFF   angry  \n",
       "1  Have you seen minions??  others  \n",
       "2          I will be marry   happy  \n",
       "3                      Brb  others  \n",
       "4      he is pressuring me  others  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = functions.parse_file(r\"raw_data/EmoContext/devwithlabels.txt\", \"EmoContext\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = []\n",
    "for idx,row in df.iterrows():\n",
    "    text_data.append(\"{}. {}. {}.\".format(row['turn1'], row['turn2'], row['turn3']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizer = Tokenizer(num_words=NR_WORDS, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
    "#                                   lower=True,split=' ')\n",
    "\n",
    "#tokenizer.fit_on_texts(text_data)\n",
    "\n",
    "X_test = tokenizer.texts_to_sequences(text_data)\n",
    "X_test = pad_sequences(X_test, maxlen = MAX_PROP_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_vector(word,label=None):\n",
    "    words = {\"others\": 0, \"angry\": 1, \"sad\":2, \"happy\": 3}\n",
    "    if label == None:\n",
    "        y = [0,0,0,0]\n",
    "        y[words[word]] = 1\n",
    "        return y\n",
    "    if label == word:\n",
    "        return [1,0]\n",
    "    return [0,1]\n",
    "\n",
    "Y_test_others = []\n",
    "Y_test_angry = []\n",
    "Y_test_sad = []\n",
    "Y_test_happy = []\n",
    "\n",
    "for idx,row in df.iterrows():\n",
    "    Y_test_others.append(one_hot_vector(row['label'],\"others\"))\n",
    "    Y_test_angry.append(one_hot_vector(row['label'],\"angry\"))\n",
    "    Y_test_sad.append(one_hot_vector(row['label'],\"sad\"))\n",
    "    Y_test_happy.append(one_hot_vector(row['label'],\"happy\"))\n",
    "\n",
    "Y_test_others = np.array(Y_test_others)\n",
    "Y_test_angry = np.array(Y_test_angry)\n",
    "Y_test_sad = np.array(Y_test_sad)\n",
    "Y_test_happy = np.array(Y_test_happy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 64\n",
    "lstm_out = 32\n",
    "batch_size = 128\n",
    "\n",
    "adam = optimizers.Adam(lr=0.01)\n",
    "rmsprop = optimizers.RMSprop(lr=0.01, rho=0.95, epsilon=None, decay=0.0)\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(NR_WORDS, embed_dim,input_length = X_train.shape[1],name=\"boosting_embeding\"))\n",
    "model.add(LSTM(lstm_out))\n",
    "model.add(Dense(2,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "boosting_embeding (Embedding (None, 100, 64)           320000    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 32)                12416     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 332,482\n",
      "Trainable params: 332,482\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdcheck = ModelCheckpoint(\"trained_models/best_model_val_acc{val_acc:.4f}.h5\", monitor='val_f1', save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 30160 samples, validate on 2755 samples\n",
      "Epoch 1/5\n",
      "30160/30160 [==============================] - 71s 2ms/step - loss: 0.7444 - acc: 0.8344 - f1: 0.7773 - val_loss: 0.2423 - val_acc: 0.9220 - val_f1: 0.7487\n",
      "Epoch 2/5\n",
      "30160/30160 [==============================] - 56s 2ms/step - loss: 0.3762 - acc: 0.9294 - f1: 0.8905 - val_loss: 0.2077 - val_acc: 0.9296 - val_f1: 0.7668\n",
      "Epoch 3/5\n",
      "30160/30160 [==============================] - 53s 2ms/step - loss: 0.3156 - acc: 0.9402 - f1: 0.9066 - val_loss: 0.2509 - val_acc: 0.9071 - val_f1: 0.7280\n",
      "Epoch 4/5\n",
      "30160/30160 [==============================] - 53s 2ms/step - loss: 0.2853 - acc: 0.9436 - f1: 0.9120 - val_loss: 0.2156 - val_acc: 0.9223 - val_f1: 0.7478\n",
      "Epoch 5/5\n",
      "30160/30160 [==============================] - 55s 2ms/step - loss: 0.2487 - acc: 0.9513 - f1: 0.9230 - val_loss: 0.2490 - val_acc: 0.9103 - val_f1: 0.7284\n"
     ]
    }
   ],
   "source": [
    "Y_train_angry = np.array(Y_train_angry)\n",
    "\n",
    "model_angry = clone_model(model)\n",
    "model_angry.compile(loss = 'binary_crossentropy', optimizer=\"adam\", metrics = ['accuracy', f1])\n",
    "model_angry.name = \"angry_model\"\n",
    "history = model_angry.fit(X_train, Y_train_angry,\n",
    "                    validation_data=(X_test, Y_test_angry),\n",
    "                    epochs=5, verbose=1, batch_size=batch_size,callbacks=[mdcheck],shuffle=True,\n",
    "                    class_weight={\n",
    "                        0: len(X_train) / len(np.where(Y_train_angry[:,0]==1.0)[0]),\n",
    "                        1: len(X_train) / len(np.where(Y_train_angry[:,1]==1.0)[0]),\n",
    "                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(model_angry,indices=[{\"indices\":[\"turn1\",\"turn2\",\"turn3\"],\"NR_WORDS\":NR_WORDS,\"MAX_PROP_LENGTH\":MAX_PROP_LENGTH}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 30160 samples, validate on 2755 samples\n",
      "Epoch 1/5\n",
      "30160/30160 [==============================] - 62s 2ms/step - loss: 0.7218 - acc: 0.8688 - f1: 0.8060 - val_loss: 0.3959 - val_acc: 0.8715 - val_f1: 0.6481\n",
      "Epoch 2/5\n",
      "30160/30160 [==============================] - 57s 2ms/step - loss: 0.5201 - acc: 0.9143 - f1: 0.8655 - val_loss: 0.2219 - val_acc: 0.9162 - val_f1: 0.7051\n",
      "Epoch 3/5\n",
      "30160/30160 [==============================] - 52s 2ms/step - loss: 0.4326 - acc: 0.9263 - f1: 0.8834 - val_loss: 0.1821 - val_acc: 0.9379 - val_f1: 0.7358\n",
      "Epoch 4/5\n",
      "30160/30160 [==============================] - 52s 2ms/step - loss: 0.3627 - acc: 0.9372 - f1: 0.8999 - val_loss: 0.3820 - val_acc: 0.8505 - val_f1: 0.6245\n",
      "Epoch 5/5\n",
      "30160/30160 [==============================] - 52s 2ms/step - loss: 0.2957 - acc: 0.9490 - f1: 0.9178 - val_loss: 0.2386 - val_acc: 0.9169 - val_f1: 0.6964\n"
     ]
    }
   ],
   "source": [
    "Y_train_sad = np.array(Y_train_sad)\n",
    "\n",
    "model_sad = clone_model(model)\n",
    "model_sad.compile(loss = 'binary_crossentropy', optimizer=rmsprop, metrics = ['accuracy', f1])\n",
    "model_sad.name = \"sad_model\"\n",
    "history = model_sad.fit(X_train, Y_train_sad,\n",
    "                    validation_data=(X_test, Y_test_sad),\n",
    "                    epochs=5, verbose=1, batch_size=batch_size,callbacks=[mdcheck],\n",
    "                    class_weight={\n",
    "                        0: len(X_train) / len(np.where(Y_train_sad[:,0]==1.0)[0]),\n",
    "                        1: len(X_train) / len(np.where(Y_train_sad[:,1]==1.0)[0]),\n",
    "                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(model_sad,indices=[{\"indices\":[\"turn1\",\"turn2\",\"turn3\"],\"NR_WORDS\":NR_WORDS,\"MAX_PROP_LENGTH\":MAX_PROP_LENGTH}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 30160 samples, validate on 2755 samples\n",
      "Epoch 1/5\n",
      "30160/30160 [==============================] - 61s 2ms/step - loss: 0.7524 - acc: 0.8568 - f1: 0.7652 - val_loss: 0.3349 - val_acc: 0.8784 - val_f1: 0.6413\n",
      "Epoch 2/5\n",
      "30160/30160 [==============================] - 54s 2ms/step - loss: 0.5562 - acc: 0.9026 - f1: 0.8266 - val_loss: 0.5088 - val_acc: 0.7633 - val_f1: 0.5568\n",
      "Epoch 3/5\n",
      "30160/30160 [==============================] - 53s 2ms/step - loss: 0.4633 - acc: 0.9122 - f1: 0.8433 - val_loss: 0.5003 - val_acc: 0.7964 - val_f1: 0.5783\n",
      "Epoch 4/5\n",
      "30160/30160 [==============================] - 54s 2ms/step - loss: 0.3988 - acc: 0.9245 - f1: 0.8632 - val_loss: 0.5192 - val_acc: 0.7869 - val_f1: 0.5693\n",
      "Epoch 5/5\n",
      "30160/30160 [==============================] - 67s 2ms/step - loss: 0.3437 - acc: 0.9334 - f1: 0.8770 - val_loss: 0.5011 - val_acc: 0.7971 - val_f1: 0.5792\n"
     ]
    }
   ],
   "source": [
    "Y_train_happy = np.array(Y_train_happy)\n",
    "\n",
    "model_happy = clone_model(model)\n",
    "model_happy.compile(loss = 'binary_crossentropy', optimizer=rmsprop, metrics = ['accuracy', f1])\n",
    "model_happy.name = \"happy_model\"\n",
    "history = model_happy.fit(X_train, Y_train_happy,\n",
    "                    validation_data=(X_test, Y_test_happy),\n",
    "                    epochs=5, verbose=1, batch_size=batch_size,callbacks=[mdcheck],\n",
    "                    class_weight={\n",
    "                        0: len(X_train) / len(np.where(Y_train_happy[:,0]==1.0)[0]),\n",
    "                        1: len(X_train) / len(np.where(Y_train_happy[:,1]==1.0)[0]),\n",
    "                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(model_happy,indices=[{\"indices\":[\"turn1\",\"turn2\",\"turn3\"],\"NR_WORDS\":NR_WORDS,\"MAX_PROP_LENGTH\":MAX_PROP_LENGTH}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 30160 samples, validate on 2755 samples\n",
      "Epoch 1/5\n",
      "30160/30160 [==============================] - 76s 3ms/step - loss: 0.8209 - acc: 0.8167 - f1: 0.8132 - val_loss: 0.3435 - val_acc: 0.8606 - val_f1: 0.7620\n",
      "Epoch 2/5\n",
      "30160/30160 [==============================] - 46s 2ms/step - loss: 0.6428 - acc: 0.8663 - f1: 0.8655 - val_loss: 0.4399 - val_acc: 0.8279 - val_f1: 0.7322\n",
      "Epoch 3/5\n",
      "30160/30160 [==============================] - 46s 2ms/step - loss: 0.5564 - acc: 0.8888 - f1: 0.8878 - val_loss: 0.4147 - val_acc: 0.8192 - val_f1: 0.7261\n",
      "Epoch 4/5\n",
      "30160/30160 [==============================] - 49s 2ms/step - loss: 0.4764 - acc: 0.9070 - f1: 0.9063 - val_loss: 0.4662 - val_acc: 0.8196 - val_f1: 0.7253\n",
      "Epoch 5/5\n",
      "30160/30160 [==============================] - 53s 2ms/step - loss: 0.4021 - acc: 0.9216 - f1: 0.9210 - val_loss: 0.5352 - val_acc: 0.8069 - val_f1: 0.7135\n"
     ]
    }
   ],
   "source": [
    "Y_train_others = np.array(Y_train_others)\n",
    "\n",
    "model_others = clone_model(model)\n",
    "model_others.compile(loss = 'binary_crossentropy', optimizer=rmsprop, metrics = ['accuracy', f1])\n",
    "model_others.name = \"others_model\"\n",
    "history = model_others.fit(X_train, Y_train_others,\n",
    "                    validation_data=(X_test, Y_test_others),\n",
    "                    epochs=5, verbose=1, batch_size=batch_size,callbacks=[mdcheck],\n",
    "                    class_weight={\n",
    "                        0: len(X_train) / len(np.where(Y_train_others[:,0]==1.0)[0]),\n",
    "                        1: len(X_train) / len(np.where(Y_train_others[:,1]==1.0)[0]),\n",
    "                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(model_others,indices=[{\"indices\":[\"turn1\",\"turn2\",\"turn3\"],\"NR_WORDS\":NR_WORDS,\"MAX_PROP_LENGTH\":MAX_PROP_LENGTH}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36-test",
   "language": "python",
   "name": "py36-test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
