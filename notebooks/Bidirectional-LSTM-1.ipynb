{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"../\")\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from keras.layers import Dropout\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, Bidirectional\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras import optimizers\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\work\\Master\\TAIP\\SemEval-2019\\SemEval-2019\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>turn1</th>\n",
       "      <th>turn2</th>\n",
       "      <th>turn3</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Don't worry  I'm girl</td>\n",
       "      <td>hmm how do I know if you are</td>\n",
       "      <td>What's ur name?</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>When did I?</td>\n",
       "      <td>saw many times i think -_-</td>\n",
       "      <td>No. I never saw you</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>By</td>\n",
       "      <td>by Google Chrome</td>\n",
       "      <td>Where you live</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>U r ridiculous</td>\n",
       "      <td>I might be ridiculous but I am telling the truth.</td>\n",
       "      <td>U little disgusting whore</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Just for time pass</td>\n",
       "      <td>wt do u do 4 a living then</td>\n",
       "      <td>Maybe</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>I'm a dog person</td>\n",
       "      <td>youre so rude</td>\n",
       "      <td>Whaaaat why</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>So whatsup</td>\n",
       "      <td>Nothing much. Sitting sipping and watching TV....</td>\n",
       "      <td>What are you watching on tv?</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Ok</td>\n",
       "      <td>ok im back!!</td>\n",
       "      <td>So, how are u</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>Really?</td>\n",
       "      <td>really really really really really</td>\n",
       "      <td>Y saying so many times...i can hear you</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>Bay</td>\n",
       "      <td>in the bay</td>\n",
       "      <td>üòò love you</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>I hate my boyfriend</td>\n",
       "      <td>you got a boyfriend?</td>\n",
       "      <td>Yes</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>I will do night.</td>\n",
       "      <td>Alright. Keep me in loop.</td>\n",
       "      <td>Not giving WhatsApp no.</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>Sure go ahead</td>\n",
       "      <td>Many thanks once again!</td>\n",
       "      <td>Love you too</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad bad! That's the bad kind of bad.</td>\n",
       "      <td>I have no gf</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>Ok get it......</td>\n",
       "      <td>I made it an option</td>\n",
       "      <td>Ok</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>Money money and lots of moneyüòçüòç</td>\n",
       "      <td>I need to get it tailored but I'm in love with...</td>\n",
       "      <td>üòÅüòÅ</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>My gf left ne</td>\n",
       "      <td>Get over it. Go out with someone else.</td>\n",
       "      <td>Me*</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>get lost</td>\n",
       "      <td>I know you guys want to loose to me always.</td>\n",
       "      <td>I don't want to talk u any more</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>You are lying and i know that</td>\n",
       "      <td>I KNOW YOU'RE LYING, AB BYS</td>\n",
       "      <td>üò≠üò≠</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>Ur creator is very bad</td>\n",
       "      <td>you are only the creator of your brain.</td>\n",
       "      <td>üòë</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                            turn1  \\\n",
       "0    0            Don't worry  I'm girl   \n",
       "1    1                      When did I?   \n",
       "2    2                               By   \n",
       "3    3                   U r ridiculous   \n",
       "4    4               Just for time pass   \n",
       "5    5                 I'm a dog person   \n",
       "6    6                       So whatsup   \n",
       "7    7                               Ok   \n",
       "8    8                          Really?   \n",
       "9    9                              Bay   \n",
       "10  10              I hate my boyfriend   \n",
       "11  11                 I will do night.   \n",
       "12  12                    Sure go ahead   \n",
       "13  13                              Bad   \n",
       "14  14                  Ok get it......   \n",
       "15  15  Money money and lots of moneyüòçüòç   \n",
       "16  16                    My gf left ne   \n",
       "17  17                         get lost   \n",
       "18  18    You are lying and i know that   \n",
       "19  19           Ur creator is very bad   \n",
       "\n",
       "                                                turn2  \\\n",
       "0                        hmm how do I know if you are   \n",
       "1                          saw many times i think -_-   \n",
       "2                                    by Google Chrome   \n",
       "3   I might be ridiculous but I am telling the truth.   \n",
       "4                          wt do u do 4 a living then   \n",
       "5                                       youre so rude   \n",
       "6   Nothing much. Sitting sipping and watching TV....   \n",
       "7                                        ok im back!!   \n",
       "8                  really really really really really   \n",
       "9                                          in the bay   \n",
       "10                               you got a boyfriend?   \n",
       "11                          Alright. Keep me in loop.   \n",
       "12                            Many thanks once again!   \n",
       "13               Bad bad! That's the bad kind of bad.   \n",
       "14                                I made it an option   \n",
       "15  I need to get it tailored but I'm in love with...   \n",
       "16             Get over it. Go out with someone else.   \n",
       "17        I know you guys want to loose to me always.   \n",
       "18                        I KNOW YOU'RE LYING, AB BYS   \n",
       "19            you are only the creator of your brain.   \n",
       "\n",
       "                                      turn3   label  \n",
       "0                           What's ur name?  others  \n",
       "1                       No. I never saw you   angry  \n",
       "2                            Where you live  others  \n",
       "3                 U little disgusting whore   angry  \n",
       "4                                     Maybe  others  \n",
       "5                               Whaaaat why  others  \n",
       "6              What are you watching on tv?  others  \n",
       "7                             So, how are u  others  \n",
       "8   Y saying so many times...i can hear you  others  \n",
       "9                                üòò love you  others  \n",
       "10                                      Yes   angry  \n",
       "11                  Not giving WhatsApp no.  others  \n",
       "12                             Love you too  others  \n",
       "13                             I have no gf     sad  \n",
       "14                                       Ok  others  \n",
       "15                                       üòÅüòÅ   happy  \n",
       "16                                      Me*     sad  \n",
       "17          I don't want to talk u any more   angry  \n",
       "18                                       üò≠üò≠     sad  \n",
       "19                                        üòë     sad  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import *\n",
    "print(os.getcwd())\n",
    "df = functions.parse_file(r\"raw_data/EmoContext/train.txt\", \"EmoContext\")\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = functions.parse_file(r\"raw_data/EmoContext/testwithoutlabels.txt\", \"EmoContext\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = []\n",
    "for idx,row in df.iterrows():\n",
    "    text_data.append(\" {} fullstop {} fullstop {} fullstop\".format(row['turn1'], row['turn2'], row['turn3']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_text_data = []\n",
    "for idx,row in df_test.iterrows():\n",
    "    full_text_data.append(\" {} fullstop {} fullstop {} fullstop\".format(row['turn1'], row['turn2'], row['turn3']))\n",
    "full_text_data.extend(text_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoticons_map = {\n",
    "    'üòò': ' emoticon',\n",
    "    'üòç': ' happyemoticon',\n",
    "    'üòÅ': ' happyemoticon',\n",
    "    'üò≠': ' sademoticon',\n",
    "    'üòë': ' sademoticon',\n",
    "    'üòª': ' happyemoticon',\n",
    "    'üòÇ': ' happyemoticon',\n",
    "    'üëç': ' emoticon',\n",
    "    'üòÄ': ' happyemoticon',\n",
    "    ':D': ' happyemoticon',\n",
    "    'üôÇ':  ' happyemoticon',\n",
    "    '<3': ' happyemoticon',\n",
    "    'üòì' : ' sademoticon',\n",
    "    'üòí' : ' angryemoticon',\n",
    "    'üòà' : ' emoticon',\n",
    "    'üëø' : ' angryemoticon',\n",
    "    'üñë' : ' happyemoticon',\n",
    "    'üòæ' : ' emoticon',\n",
    "    'üò†' : ' angryemoticon',\n",
    "    'üëª' : ' emoticon',\n",
    "    ':(' : ' sademoticon',\n",
    "    ':)' : ' happyemoticon',\n",
    "    'xD' : ' happyemoticon',\n",
    "    'üíî' : ' sademoticon',\n",
    "    'üò•' : ' emoticon',\n",
    "    'üòû' : ' sademoticon',\n",
    "    'üò§' : ' angryemoticon',\n",
    "    'üòÉ' : ' happyemoticon',\n",
    "    'üò¶' : ' sademoticon',\n",
    "    ':3' : ' emoticon',\n",
    "    'üòº' : ' emoticon',\n",
    "    'üòè' : ' happyemoticon',\n",
    "    'üò±' : ' sademoticon',\n",
    "    'üò¨' : ' sademoticon',\n",
    "    'üôÅ' : ' sademoticon',\n",
    "    '</3' : ' sademoticon',\n",
    "    'üò∫' : ' happyemoticon',\n",
    "    'üò£' : ' angryemoticon',\n",
    "    'üò¢' : ' sademoticon',\n",
    "    'üòÜ' : ' happyemoticon',\n",
    "    'üòÑ' : ' happyemoticon',\n",
    "    'üòÖ' : ' happyemoticon',\n",
    "    ':-)' : ' happyemoticon',\n",
    "    'üòä' : ' happyemoticon',\n",
    "    'üòï' : ' sademoticon',\n",
    "    'üòΩ' : ' happyemoticon',\n",
    "    'üôÄ' : ' angryemoticon',\n",
    "    'ü§£' : ' happyemoticon',\n",
    "    'ü§ê' : ' emoticon',\n",
    "    'üò°' : ' sademoticon',\n",
    "    'üëå' : ' happyemoticon', \n",
    "    'üòÆ' : ' emoticon',\n",
    "    '‚ù§Ô∏è' : ' happyemoticon',\n",
    "    'üôÑ' : ' happyemoticon',\n",
    "    'üòø' : ' sademoticon',\n",
    "    'üòâ' : ' happyemoticon',\n",
    "    'üòã' : ' happyemoticon',\n",
    "    'üòê' : ' emoticon',\n",
    "    'üòπ' : ' happyemoticon',\n",
    "    'üò¥' : ' sademoticon',\n",
    "    'üí§' : ' emoticon',\n",
    "    'üòú' : ' happyemoticon',\n",
    "    'üòá' : ' happyemoticon',\n",
    "    'üòî' : ' sademoticon',\n",
    "    'üò©' : ' sademoticon',\n",
    "    '‚ù§' : ' happyemoticon',\n",
    "    'üò≤' : ' emoticon',\n",
    "    'üò´' : ' sademoticon',\n",
    "    'üò≥' : ' sademoticon',\n",
    "    'üò∞' : ' sademoticon',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_words_df = pd.read_csv('bad-words.csv')\n",
    "#bad_words_df['jigaboo']\n",
    "bad_words = list(bad_words_df['jigaboo'])\n",
    "bad_words.sort(key = lambda s: len(s))\n",
    "bad_words = bad_words[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(text_data)):\n",
    "    for k in emoticons_map.keys():\n",
    "        if text_data[i].find(k) >= 0:\n",
    "            text_data[i] = text_data[i].replace(k, emoticons_map[k])\n",
    "    for bw in bad_words:\n",
    "        bw = \" {} \".format(bw)\n",
    "        if text_data[i].find(bw) >= 0:\n",
    "            text_data[i] = text_data[i].replace(bw, ' badword ')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(full_text_data)):\n",
    "    for k in emoticons_map.keys():\n",
    "        if full_text_data[i].find(k) >= 0:\n",
    "            full_text_data[i] = full_text_data[i].replace(k, emoticons_map[k])\n",
    "    for bw in bad_words:\n",
    "        bw = \" {} \".format(bw)\n",
    "        if full_text_data[i].find(bw) >= 0:\n",
    "            full_text_data[i] = full_text_data[i].replace(bw, ' badword ')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(y_true, y_pred):\n",
    "    y_pred = K.round(y_pred)\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return K.mean(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "NR_WORDS = 17000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=NR_WORDS, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
    "                                   lower=True,split=' ')\n",
    "\n",
    "tokenizer.fit_on_texts(full_text_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tokenizer.texts_to_sequences(text_data)\n",
    "X = pad_sequences(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = {\"others\": 0, \"angry\": 1, \"sad\":2, \"happy\": 3}\n",
    "\n",
    "def one_hot_vector(word):\n",
    "    y = [0,0,0,0]\n",
    "    y[words[word]] = 1\n",
    "    return y\n",
    "\n",
    "Y = []\n",
    "\n",
    "for idx,row in df.iterrows():\n",
    "    Y.append(one_hot_vector(row['label']))\n",
    "\n",
    "Y = np.array(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 256\n",
    "lstm_out = 128\n",
    "batch_size = 128\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(NR_WORDS, embed_dim,input_length = X.shape[1]))\n",
    "model.add(Bidirectional(LSTM(lstm_out)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(4,activation='softmax'))\n",
    "adam = optimizers.Adam(lr=0.01)\n",
    "rmsprop = optimizers.RMSprop(lr=0.005, rho=0.9, epsilon=None, decay=0.0)\n",
    "model.compile(loss = 'binary_crossentropy', optimizer=rmsprop, metrics = ['accuracy', f1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 160, 256)          4352000   \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 256)               394240    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 1028      \n",
      "=================================================================\n",
      "Total params: 4,747,268\n",
      "Trainable params: 4,747,268\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.fit(X_train, Y_train, batch_size = 128, nb_epoch = 3, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#K.set_value(model.optimizer.lr, 0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 22620 samples, validate on 7540 samples\n",
      "Epoch 1/1\n",
      "22620/22620 [==============================] - 713s 32ms/step - loss: 0.2614 - acc: 0.8959 - f1: 0.7363 - val_loss: 0.1956 - val_acc: 0.9283 - val_f1: 0.8391\n",
      "Train on 22620 samples, validate on 7540 samples\n",
      "Epoch 1/1\n",
      "22620/22620 [==============================] - 741s 33ms/step - loss: 0.1654 - acc: 0.9383 - f1: 0.8586 - val_loss: 0.1457 - val_acc: 0.9445 - val_f1: 0.8724\n",
      "Train on 22620 samples, validate on 7540 samples\n",
      "Epoch 1/1\n",
      "22620/22620 [==============================] - 655s 29ms/step - loss: 0.1337 - acc: 0.9515 - f1: 0.8903 - val_loss: 0.1223 - val_acc: 0.9543 - val_f1: 0.8937\n",
      "Train on 22620 samples, validate on 7540 samples\n",
      "Epoch 1/1\n",
      "22620/22620 [==============================] - 459s 20ms/step - loss: 0.1143 - acc: 0.9578 - f1: 0.9042 - val_loss: 0.1020 - val_acc: 0.9615 - val_f1: 0.9109\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "# prepare cross validation\n",
    "kfold = KFold(n_splits=4)\n",
    "Y_train = np.array(Y_train)\n",
    "# enumerate splits\n",
    "for train, validation in kfold.split(X_train):\n",
    "    history = model.fit(X_train[train], Y_train[train],\n",
    "                    validation_data=(X_train[validation], Y_train[validation]),\n",
    "                    epochs=1, verbose=1, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-6c813e833929>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mev_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Score: %.3f\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mev_result\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Validation Accuracy: %.3f\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mev_result\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"F1 score: %.3f\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mev_result\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "ev_result = model.evaluate(X_test, Y_test, verbose = 2, batch_size = batch_size)\n",
    "print(\"Score: %.3f\" % (ev_result[0]))\n",
    "print(\"Validation Accuracy: %.3f\" % (ev_result[1]))\n",
    "print(\"F1 score: %.3f\" % (ev_result[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"simple_model.json\", \"w\") as outfile:\n",
    "    outfile.write(model_json)\n",
    "model.save_weights(\"simple_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>turn1</th>\n",
       "      <th>turn2</th>\n",
       "      <th>turn3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Hmm</td>\n",
       "      <td>What does your bio mean?</td>\n",
       "      <td>I don‚Äôt have any bio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>What you like</td>\n",
       "      <td>very little things</td>\n",
       "      <td>Ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>How so?</td>\n",
       "      <td>I want to fuck babu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>what did you guess</td>\n",
       "      <td>what what</td>\n",
       "      <td>fuck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>We ?</td>\n",
       "      <td>of course we will!</td>\n",
       "      <td>What gender movies you like??</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id               turn1                     turn2  \\\n",
       "0  0                 Hmm  What does your bio mean?   \n",
       "1  1       What you like        very little things   \n",
       "2  2                 Yes                   How so?   \n",
       "3  3  what did you guess                 what what   \n",
       "4  4                We ?        of course we will!   \n",
       "\n",
       "                           turn3  \n",
       "0           I don‚Äôt have any bio  \n",
       "1                            Ok   \n",
       "2            I want to fuck babu  \n",
       "3                           fuck  \n",
       "4  What gender movies you like??  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = functions.parse_file(r\"raw_data/EmoContext/testwithoutlabels.txt\", \"EmoContext\")\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = []\n",
    "\n",
    "for idx,row in df_test.iterrows():\n",
    "    text_data.append(\" {} fullstop {} fullstop {} fullstop\".format(row['turn1'], row['turn2'], row['turn3']))\n",
    "    \n",
    "for i in range(0, len(text_data)):\n",
    "    for k in emoticons_map.keys():\n",
    "        if text_data[i].find(k) >= 0:\n",
    "            text_data[i] = text_data[i].replace(k, emoticons_map[k])\n",
    "    for bw in bad_words:\n",
    "        bw = \" {} \".format(bw)\n",
    "        if text_data[i].find(bw) >= 0:\n",
    "            text_data[i] = text_data[i].replace(bw, ' badword ')    \n",
    "    \n",
    "X_test = tokenizer.texts_to_sequences(text_data)\n",
    "X_test = pad_sequences(X_test, maxlen = X.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5509/5509 [==============================] - 21s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "res = model.predict(X_test, batch_size=128, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "revers_words = {0:\"others\", 1:\"angry\", 2:\"sad\", 3:\"happy\"}\n",
    "\n",
    "def softmax_convert(res):\n",
    "    max_i = 0\n",
    "    max_v = 0\n",
    "    for i in range(0,4):\n",
    "        if res[i] > max_v:\n",
    "            max_v = res[i]\n",
    "            max_i = i\n",
    "    return revers_words[max_i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for r in res:\n",
    "    results.append(softmax_convert(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['label'] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.to_csv(\"test.txt\",index=False , sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tokenizer.word_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
