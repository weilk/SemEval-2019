{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from keras.layers import Dropout\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, Bidirectional\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras import optimizers\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\work\\Master\\TAIP\\SemEval-2019\\SemEval-2019\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'functions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-f9816e7b4908>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunctions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr\"raw_data/EmoContext/train.txt\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"EmoContext\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'functions' is not defined"
     ]
    }
   ],
   "source": [
    "from utils import *\n",
    "df = functions.parse_file(r\"raw_data/EmoContext/train.txt\", \"EmoContext\")\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = functions.parse_file(r\"testwithoutlabels.txt\", \"EmoContext\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = []\n",
    "for idx,row in df.iterrows():\n",
    "    text_data.append(\" {} fullstop {} fullstop {} fullstop\".format(row['turn1'], row['turn2'], row['turn3']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_text_data = []\n",
    "for idx,row in df_test.iterrows():\n",
    "    full_text_data.append(\" {} fullstop {} fullstop {} fullstop\".format(row['turn1'], row['turn2'], row['turn3']))\n",
    "full_text_data.extend(text_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoticons_map = {\n",
    "    'üòò': ' emoticon',\n",
    "    'üòç': ' happyemoticon',\n",
    "    'üòÅ': ' happyemoticon',\n",
    "    'üò≠': ' sademoticon',\n",
    "    'üòë': ' sademoticon',\n",
    "    'üòª': ' happyemoticon',\n",
    "    'üòÇ': ' happyemoticon',\n",
    "    'üëç': ' emoticon',\n",
    "    'üòÄ': ' happyemoticon',\n",
    "    ':D': ' happyemoticon',\n",
    "    'üôÇ':  ' happyemoticon',\n",
    "    '<3': ' happyemoticon',\n",
    "    'üòì' : ' sademoticon',\n",
    "    'üòí' : ' angryemoticon',\n",
    "    'üòà' : ' emoticon',\n",
    "    'üëø' : ' angryemoticon',\n",
    "    'üñë' : ' happyemoticon',\n",
    "    'üòæ' : ' emoticon',\n",
    "    'üò†' : ' angryemoticon',\n",
    "    'üëª' : ' emoticon',\n",
    "    ':(' : ' sademoticon',\n",
    "    ':)' : ' happyemoticon',\n",
    "    'xD' : ' happyemoticon',\n",
    "    'üíî' : ' sademoticon',\n",
    "    'üò•' : ' emoticon',\n",
    "    'üòû' : ' sademoticon',\n",
    "    'üò§' : ' angryemoticon',\n",
    "    'üòÉ' : ' happyemoticon',\n",
    "    'üò¶' : ' sademoticon',\n",
    "    ':3' : ' emoticon',\n",
    "    'üòº' : ' emoticon',\n",
    "    'üòè' : ' happyemoticon',\n",
    "    'üò±' : ' sademoticon',\n",
    "    'üò¨' : ' sademoticon',\n",
    "    'üôÅ' : ' sademoticon',\n",
    "    '</3' : ' sademoticon',\n",
    "    'üò∫' : ' happyemoticon',\n",
    "    'üò£' : ' angryemoticon',\n",
    "    'üò¢' : ' sademoticon',\n",
    "    'üòÜ' : ' happyemoticon',\n",
    "    'üòÑ' : ' happyemoticon',\n",
    "    'üòÖ' : ' happyemoticon',\n",
    "    ':-)' : ' happyemoticon',\n",
    "    'üòä' : ' happyemoticon',\n",
    "    'üòï' : ' sademoticon',\n",
    "    'üòΩ' : ' happyemoticon',\n",
    "    'üôÄ' : ' angryemoticon',\n",
    "    'ü§£' : ' happyemoticon',\n",
    "    'ü§ê' : ' emoticon',\n",
    "    'üò°' : ' sademoticon',\n",
    "    'üëå' : ' happyemoticon', \n",
    "    'üòÆ' : ' emoticon',\n",
    "    '‚ù§Ô∏è' : ' happyemoticon',\n",
    "    'üôÑ' : ' happyemoticon',\n",
    "    'üòø' : ' sademoticon',\n",
    "    'üòâ' : ' happyemoticon',\n",
    "    'üòã' : ' happyemoticon',\n",
    "    'üòê' : ' emoticon',\n",
    "    'üòπ' : ' happyemoticon',\n",
    "    'üò¥' : ' sademoticon',\n",
    "    'üí§' : ' emoticon',\n",
    "    'üòú' : ' happyemoticon',\n",
    "    'üòá' : ' happyemoticon',\n",
    "    'üòî' : ' sademoticon',\n",
    "    'üò©' : ' sademoticon',\n",
    "    '‚ù§' : ' happyemoticon',\n",
    "    'üò≤' : ' emoticon',\n",
    "    'üò´' : ' sademoticon',\n",
    "    'üò≥' : ' sademoticon',\n",
    "    'üò∞' : ' sademoticon',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_words_df = pd.read_csv('bad-words.csv')\n",
    "#bad_words_df['jigaboo']\n",
    "bad_words = list(bad_words_df['jigaboo'])\n",
    "bad_words.sort(key = lambda s: len(s))\n",
    "bad_words = bad_words[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(text_data)):\n",
    "    for k in emoticons_map.keys():\n",
    "        if text_data[i].find(k) >= 0:\n",
    "            text_data[i] = text_data[i].replace(k, emoticons_map[k])\n",
    "    for bw in bad_words:\n",
    "        bw = \" {} \".format(bw)\n",
    "        if text_data[i].find(bw) >= 0:\n",
    "            text_data[i] = text_data[i].replace(bw, ' badword ')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(full_text_data)):\n",
    "    for k in emoticons_map.keys():\n",
    "        if full_text_data[i].find(k) >= 0:\n",
    "            full_text_data[i] = full_text_data[i].replace(k, emoticons_map[k])\n",
    "    for bw in bad_words:\n",
    "        bw = \" {} \".format(bw)\n",
    "        if full_text_data[i].find(bw) >= 0:\n",
    "            full_text_data[i] = full_text_data[i].replace(bw, ' badword ')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(y_true, y_pred):\n",
    "    y_pred = K.round(y_pred)\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return K.mean(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "NR_WORDS = 17000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=NR_WORDS, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
    "                                   lower=True,split=' ')\n",
    "\n",
    "tokenizer.fit_on_texts(full_text_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tokenizer.texts_to_sequences(text_data)\n",
    "X = pad_sequences(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = {\"others\": 0, \"angry\": 1, \"sad\":2, \"happy\": 3}\n",
    "\n",
    "def one_hot_vector(word):\n",
    "    y = [0,0,0,0]\n",
    "    y[words[word]] = 1\n",
    "    return y\n",
    "\n",
    "Y = []\n",
    "\n",
    "for idx,row in df.iterrows():\n",
    "    Y.append(one_hot_vector(row['label']))\n",
    "\n",
    "Y = np.array(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 256\n",
    "lstm_out = 128\n",
    "batch_size = 128\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(NR_WORDS, embed_dim,input_length = X.shape[1]))\n",
    "model.add(Bidirectional(LSTM(lstm_out)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(4,activation='softmax'))\n",
    "adam = optimizers.Adam(lr=0.01)\n",
    "rmsprop = optimizers.RMSprop(lr=0.005, rho=0.9, epsilon=None, decay=0.0)\n",
    "sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss = 'binary_crossentropy', optimizer=rmsprop, metrics = ['accuracy', f1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 160, 256)          4352000   \n",
      "_________________________________________________________________\n",
      "bidirectional_4 (Bidirection (None, 256)               394240    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 4)                 1028      \n",
      "=================================================================\n",
      "Total params: 4,747,268\n",
      "Trainable params: 4,747,268\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.fit(X_train, Y_train, batch_size = 128, nb_epoch = 3, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.set_value(model.optimizer.lr, 0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 22620 samples, validate on 7540 samples\n",
      "Epoch 1/1\n",
      "22620/22620 [==============================] - 452s 20ms/step - loss: 0.2618 - acc: 0.8956 - f1: 0.7318 - val_loss: 0.2207 - val_acc: 0.9116 - val_f1: 0.7933\n",
      "Train on 22620 samples, validate on 7540 samples\n",
      "Epoch 1/1\n",
      "22620/22620 [==============================] - 449s 20ms/step - loss: 0.1644 - acc: 0.9387 - f1: 0.8606 - val_loss: 0.1449 - val_acc: 0.9458 - val_f1: 0.8767\n",
      "Train on 22620 samples, validate on 7540 samples\n",
      "Epoch 1/1\n",
      "22620/22620 [==============================] - 456s 20ms/step - loss: 0.1342 - acc: 0.9511 - f1: 0.8897 - val_loss: 0.1265 - val_acc: 0.9545 - val_f1: 0.8953\n",
      "Train on 22620 samples, validate on 7540 samples\n",
      "Epoch 1/1\n",
      "22620/22620 [==============================] - 461s 20ms/step - loss: 0.1141 - acc: 0.9584 - f1: 0.9063 - val_loss: 0.0977 - val_acc: 0.9640 - val_f1: 0.9173\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "# prepare cross validation\n",
    "kfold = KFold(n_splits=4)\n",
    "Y_train = np.array(Y_train)\n",
    "# enumerate splits\n",
    "for train, validation in kfold.split(X_train):\n",
    "    history = model.fit(X_train[train], Y_train[train],\n",
    "                    validation_data=(X_train[validation], Y_train[validation]),\n",
    "                    epochs=1, verbose=1, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ev_result = model.evaluate(X_test, Y_test, verbose = 2, batch_size = batch_size)\n",
    "print(\"Score: %.3f\" % (ev_result[0]))\n",
    "print(\"Validation Accuracy: %.3f\" % (ev_result[1]))\n",
    "print(\"F1 score: %.3f\" % (ev_result[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"simple_model.json\", \"w\") as outfile:\n",
    "    outfile.write(model_json)\n",
    "model.save_weights(\"simple_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>turn1</th>\n",
       "      <th>turn2</th>\n",
       "      <th>turn3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Hmm</td>\n",
       "      <td>What does your bio mean?</td>\n",
       "      <td>I don‚Äôt have any bio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>What you like</td>\n",
       "      <td>very little things</td>\n",
       "      <td>Ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>How so?</td>\n",
       "      <td>I want to fuck babu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>what did you guess</td>\n",
       "      <td>what what</td>\n",
       "      <td>fuck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>We ?</td>\n",
       "      <td>of course we will!</td>\n",
       "      <td>What gender movies you like??</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id               turn1                     turn2  \\\n",
       "0  0                 Hmm  What does your bio mean?   \n",
       "1  1       What you like        very little things   \n",
       "2  2                 Yes                   How so?   \n",
       "3  3  what did you guess                 what what   \n",
       "4  4                We ?        of course we will!   \n",
       "\n",
       "                           turn3  \n",
       "0           I don‚Äôt have any bio  \n",
       "1                            Ok   \n",
       "2            I want to fuck babu  \n",
       "3                           fuck  \n",
       "4  What gender movies you like??  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = functions.parse_file(r\"testwithoutlabels.txt\", \"EmoContext\")\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = []\n",
    "\n",
    "for idx,row in df_test.iterrows():\n",
    "    text_data.append(\" {} fullstop {} fullstop {} fullstop\".format(row['turn1'], row['turn2'], row['turn3']))\n",
    "    \n",
    "for i in range(0, len(text_data)):\n",
    "    for k in emoticons_map.keys():\n",
    "        if text_data[i].find(k) >= 0:\n",
    "            text_data[i] = text_data[i].replace(k, emoticons_map[k])\n",
    "    for bw in bad_words:\n",
    "        bw = \" {} \".format(bw)\n",
    "        if text_data[i].find(bw) >= 0:\n",
    "            text_data[i] = text_data[i].replace(bw, ' badword ')    \n",
    "    \n",
    "X_test = tokenizer.texts_to_sequences(text_data)\n",
    "X_test = pad_sequences(X_test, maxlen = X.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5509/5509 [==============================] - 19s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "res = model.predict(X_test, batch_size=128, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "revers_words = {0:\"others\", 1:\"angry\", 2:\"sad\", 3:\"happy\"}\n",
    "\n",
    "def softmax_convert(res):\n",
    "    max_i = 0\n",
    "    max_v = 0\n",
    "    for i in range(0,4):\n",
    "        if res[i] > max_v:\n",
    "            max_v = res[i]\n",
    "            max_i = i\n",
    "    return revers_words[max_i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for r in res:\n",
    "    results.append(softmax_convert(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['label'] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>turn1</th>\n",
       "      <th>turn2</th>\n",
       "      <th>turn3</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Hmm</td>\n",
       "      <td>What does your bio mean?</td>\n",
       "      <td>I don‚Äôt have any bio</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>What you like</td>\n",
       "      <td>very little things</td>\n",
       "      <td>Ok</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>How so?</td>\n",
       "      <td>I want to fuck babu</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>what did you guess</td>\n",
       "      <td>what what</td>\n",
       "      <td>fuck</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>We ?</td>\n",
       "      <td>of course we will!</td>\n",
       "      <td>What gender movies you like??</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Where are you now?</td>\n",
       "      <td>At home just about to have breakfast...</td>\n",
       "      <td>what are you eating?</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>That was a joke btw...</td>\n",
       "      <td>it was</td>\n",
       "      <td>Yes üòÅ</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Who d hell s he</td>\n",
       "      <td>johnny depp...duh?</td>\n",
       "      <td>Who she</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>yes, good advice</td>\n",
       "      <td>best advice ...</td>\n",
       "      <td>i great thx</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>Nice to meet u</td>\n",
       "      <td>Hi, nice to meet you too! üò∏üòÇ</td>\n",
       "      <td>üòÅ</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>Yupp</td>\n",
       "      <td>why?</td>\n",
       "      <td>Don't know I'm tired</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>Software</td>\n",
       "      <td>Software what? I plan on going for development...</td>\n",
       "      <td>I am into android development stuff</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>Very nice</td>\n",
       "      <td>Thanks!! :)</td>\n",
       "      <td>R u know tamil</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>First  you  hurt me</td>\n",
       "      <td>okay</td>\n",
       "      <td>So I talked  rude</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>Love you üôä</td>\n",
       "      <td>you don't recognize me? üòè</td>\n",
       "      <td>I love you üôä</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>In India Fogg is going on</td>\n",
       "      <td>MumbaiIndians getting routed!!!</td>\n",
       "      <td>Ohh really</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>is my grammar perfect or should I need to lear...</td>\n",
       "      <td>Yes, it is possible.</td>\n",
       "      <td>thank you</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>by</td>\n",
       "      <td>In Suits.</td>\n",
       "      <td>have good day</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>I don‚Äôt know what to write</td>\n",
       "      <td>what are you writing about?</td>\n",
       "      <td>for my profile picture I mean</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>so you make jokes. i already got that.</td>\n",
       "      <td>that was a good joke i laughed üëç</td>\n",
       "      <td>do you read newspapers</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>Yeah mee too</td>\n",
       "      <td>Me too! All my friends are also excited</td>\n",
       "      <td>Ohhh so funny</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>Thanks</td>\n",
       "      <td>you're welcome! üòÅüòÅüòÅüòÅ</td>\n",
       "      <td>Can you help me</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>Offer?</td>\n",
       "      <td>You've already enrolled in the offer. If this ...</td>\n",
       "      <td>When it start again?</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>Uhhhmm whyy??</td>\n",
       "      <td>not you ...</td>\n",
       "      <td>No im really a bad bitch</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>sure will u cal me ni8</td>\n",
       "      <td>Ok</td>\n",
       "      <td>then</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>About what I just told</td>\n",
       "      <td>I SHOULD</td>\n",
       "      <td>You drunk? üòÇ</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>Yeaaa black panther</td>\n",
       "      <td>Black Panther teaser Don't why it was that hard.</td>\n",
       "      <td>It was an awesome movie</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>now dont give me a chance to be an danger evil</td>\n",
       "      <td>That's because you don't give yourself a chance.</td>\n",
       "      <td>i give</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>Watch spitsvilla at 7 p.m today</td>\n",
       "      <td>both are tough matches, would be fun to watch!</td>\n",
       "      <td>I love that show</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>Uuu</td>\n",
       "      <td>no i'n not !! what's wrong with you ?!?!</td>\n",
       "      <td>I hate uuu</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                                              turn1  \\\n",
       "0    0                                                Hmm   \n",
       "1    1                                      What you like   \n",
       "2    2                                                Yes   \n",
       "3    3                                 what did you guess   \n",
       "4    4                                               We ?   \n",
       "5    5                                 Where are you now?   \n",
       "6    6                             That was a joke btw...   \n",
       "7    7                                    Who d hell s he   \n",
       "8    8                                   yes, good advice   \n",
       "9    9                                     Nice to meet u   \n",
       "10  10                                               Yupp   \n",
       "11  11                                           Software   \n",
       "12  12                                         Very nice    \n",
       "13  13                                First  you  hurt me   \n",
       "14  14                                         Love you üôä   \n",
       "15  15                          In India Fogg is going on   \n",
       "16  16  is my grammar perfect or should I need to lear...   \n",
       "17  17                                                 by   \n",
       "18  18                         I don‚Äôt know what to write   \n",
       "19  19             so you make jokes. i already got that.   \n",
       "20  20                                       Yeah mee too   \n",
       "21  21                                             Thanks   \n",
       "22  22                                             Offer?   \n",
       "23  23                                      Uhhhmm whyy??   \n",
       "24  24                             sure will u cal me ni8   \n",
       "25  25                             About what I just told   \n",
       "26  26                                Yeaaa black panther   \n",
       "27  27     now dont give me a chance to be an danger evil   \n",
       "28  28                    Watch spitsvilla at 7 p.m today   \n",
       "29  29                                                Uuu   \n",
       "\n",
       "                                                turn2  \\\n",
       "0                            What does your bio mean?   \n",
       "1                                  very little things   \n",
       "2                                             How so?   \n",
       "3                                           what what   \n",
       "4                                  of course we will!   \n",
       "5             At home just about to have breakfast...   \n",
       "6                                              it was   \n",
       "7                                  johnny depp...duh?   \n",
       "8                                     best advice ...   \n",
       "9                        Hi, nice to meet you too! üò∏üòÇ   \n",
       "10                                               why?   \n",
       "11  Software what? I plan on going for development...   \n",
       "12                                        Thanks!! :)   \n",
       "13                                               okay   \n",
       "14                          you don't recognize me? üòè   \n",
       "15                    MumbaiIndians getting routed!!!   \n",
       "16                               Yes, it is possible.   \n",
       "17                                          In Suits.   \n",
       "18                        what are you writing about?   \n",
       "19                   that was a good joke i laughed üëç   \n",
       "20            Me too! All my friends are also excited   \n",
       "21                               you're welcome! üòÅüòÅüòÅüòÅ   \n",
       "22  You've already enrolled in the offer. If this ...   \n",
       "23                                        not you ...   \n",
       "24                                                 Ok   \n",
       "25                                           I SHOULD   \n",
       "26   Black Panther teaser Don't why it was that hard.   \n",
       "27   That's because you don't give yourself a chance.   \n",
       "28     both are tough matches, would be fun to watch!   \n",
       "29           no i'n not !! what's wrong with you ?!?!   \n",
       "\n",
       "                                  turn3   label  \n",
       "0                  I don‚Äôt have any bio  others  \n",
       "1                                   Ok   others  \n",
       "2                   I want to fuck babu     sad  \n",
       "3                                  fuck   angry  \n",
       "4         What gender movies you like??  others  \n",
       "5                  what are you eating?  others  \n",
       "6                                 Yes üòÅ   happy  \n",
       "7                               Who she  others  \n",
       "8                           i great thx  others  \n",
       "9                                     üòÅ   happy  \n",
       "10                 Don't know I'm tired  others  \n",
       "11  I am into android development stuff  others  \n",
       "12                      R u know tamil   others  \n",
       "13                    So I talked  rude   angry  \n",
       "14                         I love you üôä  others  \n",
       "15                           Ohh really  others  \n",
       "16                            thank you  others  \n",
       "17                        have good day  others  \n",
       "18        for my profile picture I mean  others  \n",
       "19               do you read newspapers  others  \n",
       "20                        Ohhh so funny   happy  \n",
       "21                      Can you help me  others  \n",
       "22                 When it start again?  others  \n",
       "23             No im really a bad bitch     sad  \n",
       "24                                 then  others  \n",
       "25                         You drunk? üòÇ  others  \n",
       "26              It was an awesome movie   happy  \n",
       "27                               i give  others  \n",
       "28                     I love that show  others  \n",
       "29                           I hate uuu   angry  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.to_csv(\"test.txt\",index=False , sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_tf_api_names',\n",
       " '_tf_api_names_v1',\n",
       " 'char_level',\n",
       " 'document_count',\n",
       " 'filters',\n",
       " 'fit_on_sequences',\n",
       " 'fit_on_texts',\n",
       " 'get_config',\n",
       " 'index_docs',\n",
       " 'index_word',\n",
       " 'lower',\n",
       " 'num_words',\n",
       " 'oov_token',\n",
       " 'sequences_to_matrix',\n",
       " 'sequences_to_texts',\n",
       " 'sequences_to_texts_generator',\n",
       " 'split',\n",
       " 'texts_to_matrix',\n",
       " 'texts_to_sequences',\n",
       " 'texts_to_sequences_generator',\n",
       " 'to_json',\n",
       " 'word_counts',\n",
       " 'word_docs',\n",
       " 'word_index']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17016"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.word_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
