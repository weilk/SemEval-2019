{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from keras.layers import Dropout, Input, Concatenate,concatenate\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Embedding, LSTM\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras import optimizers\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import tensorflow as tf\n",
    "\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(y_true, y_pred):\n",
    "    y_pred = K.round(y_pred)\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return K.mean(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>turn1</th>\n",
       "      <th>turn2</th>\n",
       "      <th>turn3</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>dont worry ism girl</td>\n",
       "      <td>hmm how do i know if you are</td>\n",
       "      <td>whats ur name ?  ?</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>when did in  i?</td>\n",
       "      <td>saw many times i think   -_-</td>\n",
       "      <td>no . i never saw you  .</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>by</td>\n",
       "      <td>by google chrome</td>\n",
       "      <td>where you live</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>u r ridiculous</td>\n",
       "      <td>i might be ridiculous but i am telling the tru...</td>\n",
       "      <td>u little disgusting whore</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>just for time pass</td>\n",
       "      <td>wt do u do a a living then  4</td>\n",
       "      <td>maybe</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id                  turn1  \\\n",
       "0  0  dont worry ism girl     \n",
       "1  1        when did in  i?   \n",
       "2  2                   by     \n",
       "3  3       u r ridiculous     \n",
       "4  4   just for time pass     \n",
       "\n",
       "                                               turn2  \\\n",
       "0                     hmm how do i know if you are     \n",
       "1                       saw many times i think   -_-   \n",
       "2                                 by google chrome     \n",
       "3  i might be ridiculous but i am telling the tru...   \n",
       "4                     wt do u do a a living then  4    \n",
       "\n",
       "                         turn3   label  \n",
       "0           whats ur name ?  ?  others  \n",
       "1     no . i never saw you  .    angry  \n",
       "2             where you live    others  \n",
       "3  u little disgusting whore     angry  \n",
       "4                      maybe    others  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import *\n",
    "df = functions.parse_file(r\"raw_data/EmoContext/train2.txt\", \"EmoContext\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = []\n",
    "for idx,row in df.iterrows():\n",
    "    text_data.append(\"{}. {}. {}.\".format(row['turn1'], row['turn2'], row['turn3']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "NR_WORDS = 3000\n",
    "MAX_PROP_LENGTH = 64\n",
    "tokenizer = Tokenizer(num_words=NR_WORDS, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
    "                                   lower=True,split=' ')\n",
    "\n",
    "tokenizer.fit_on_texts(text_data)\n",
    "\n",
    "X_train_1 = tokenizer.texts_to_sequences(df[\"turn1\"])\n",
    "X_train_1 = pad_sequences(X_train_1, maxlen = MAX_PROP_LENGTH)\n",
    "\n",
    "X_train_2 = tokenizer.texts_to_sequences(df[\"turn2\"])\n",
    "X_train_2 = pad_sequences(X_train_2, maxlen = MAX_PROP_LENGTH)\n",
    "\n",
    "X_train_3 = tokenizer.texts_to_sequences(df[\"turn3\"])\n",
    "X_train_3 = pad_sequences(X_train_3, maxlen = MAX_PROP_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_vector(word,label=None):\n",
    "    words = {\"others\": 0, \"angry\": 1, \"sad\":2, \"happy\": 3}\n",
    "    if label == None:\n",
    "        y = [0,0,0,0]\n",
    "        y[words[word]] = 1\n",
    "        return y\n",
    "    if label == word:\n",
    "        return [1,0]\n",
    "    return [0,1]\n",
    "\n",
    "Y_train = []\n",
    "\n",
    "for idx,row in df.iterrows():\n",
    "    Y_train.append(one_hot_vector(row['label']))\n",
    "\n",
    "Y_train = np.array(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>turn1</th>\n",
       "      <th>turn2</th>\n",
       "      <th>turn3</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>then dont ask me</td>\n",
       "      <td>youre a guy not as if you would understand</td>\n",
       "      <td>im not a guy fuck off</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>mixed things such as   ??</td>\n",
       "      <td>the things you do .  .</td>\n",
       "      <td>have you seen minions   ??</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>today ism very happy</td>\n",
       "      <td>and ism happy for you</td>\n",
       "      <td>i will be marry</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>noah bring me some</td>\n",
       "      <td>left it there oops</td>\n",
       "      <td>orb</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>it is thoo</td>\n",
       "      <td>i said soon master .  .</td>\n",
       "      <td>he is pressuring me</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id                       turn1  \\\n",
       "0  0          then dont ask me     \n",
       "1  1  mixed things such as   ??    \n",
       "2  2      today ism very happy     \n",
       "3  3        noah bring me some     \n",
       "4  4                it is thoo     \n",
       "\n",
       "                                          turn2                        turn3  \\\n",
       "0  youre a guy not as if you would understand        im not a guy fuck off     \n",
       "1                        the things you do .  .  have you seen minions   ??    \n",
       "2                      and ism happy for you               i will be marry     \n",
       "3                          left it there oops                          orb     \n",
       "4                       i said soon master .  .        he is pressuring me     \n",
       "\n",
       "    label  \n",
       "0   angry  \n",
       "1  others  \n",
       "2   happy  \n",
       "3  others  \n",
       "4  others  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = functions.parse_file(r\"raw_data/EmoContext/devwithlabels2.txt\", \"EmoContext\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = []\n",
    "for idx,row in df.iterrows():\n",
    "    text_data.append(\"{}. {}. {}.\".format(row['turn1'], row['turn2'], row['turn3']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizer = Tokenizer(num_words=NR_WORDS, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
    "#                                   lower=True,split=' ')\n",
    "\n",
    "#tokenizer.fit_on_texts(text_data)\n",
    "\n",
    "X_test_1 = tokenizer.texts_to_sequences(df[\"turn1\"])\n",
    "X_test_1 = pad_sequences(X_test_1, maxlen = MAX_PROP_LENGTH)\n",
    "\n",
    "X_test_2 = tokenizer.texts_to_sequences(df[\"turn2\"])\n",
    "X_test_2 = pad_sequences(X_test_2, maxlen = MAX_PROP_LENGTH)\n",
    "\n",
    "X_test_3 = tokenizer.texts_to_sequences(df[\"turn3\"])\n",
    "X_test_3 = pad_sequences(X_test_3, maxlen = MAX_PROP_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_vector(word,label=None):\n",
    "    words = {\"others\": 0, \"angry\": 1, \"sad\":2, \"happy\": 3}\n",
    "    if label == None:\n",
    "        y = [0,0,0,0]\n",
    "        y[words[word]] = 1\n",
    "        return y\n",
    "    if label == word:\n",
    "        return [1,0]\n",
    "    return [0,1]\n",
    "\n",
    "Y_test = []\n",
    "\n",
    "for idx,row in df.iterrows():\n",
    "    Y_test.append(one_hot_vector(row['label']))\n",
    "\n",
    "Y_test = np.array(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 64\n",
    "lstm_out = 32\n",
    "batch_size = 64\n",
    "\n",
    "adam = optimizers.Adam(lr=0.01)\n",
    "rmsprop = optimizers.RMSprop(lr=0.005, rho=0.9, epsilon=None, decay=0.0)\n",
    "\n",
    "I_1 = Input(shape=X_train_1.shape[1:])\n",
    "O_1 = Embedding(NR_WORDS, embed_dim,input_length = X_train_1.shape[1])(I_1)\n",
    "O_1 = LSTM(lstm_out, dropout=0.5)(O_1)\n",
    "\n",
    "I_2 = Input(shape=X_train_2.shape[1:])\n",
    "O_2 = Embedding(NR_WORDS, embed_dim,input_length = X_train_2.shape[1])(I_2)\n",
    "O_2 = LSTM(lstm_out, dropout=0.5)(O_2)\n",
    "\n",
    "I_3 = Input(shape=X_train_3.shape[1:])\n",
    "O_3 = Embedding(NR_WORDS, embed_dim,input_length = X_train_3.shape[1])(I_3)\n",
    "O_3 = LSTM(lstm_out, dropout=0.5)(O_3)\n",
    "\n",
    "result = concatenate([O_1,O_2,O_3])\n",
    "result = Dense(4,activation='softmax')(result)\n",
    "model = Model(inputs=[I_1,I_2,I_3], outputs=result,name=\"separate_embedings_model\")\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer=rmsprop, metrics = ['accuracy', f1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 64)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 64)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 64)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 64, 64)       192000      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 64, 64)       192000      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 64, 64)       192000      input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 32)           12416       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   (None, 32)           12416       embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   (None, 32)           12416       embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 96)           0           lstm_1[0][0]                     \n",
      "                                                                 lstm_2[0][0]                     \n",
      "                                                                 lstm_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 4)            388         concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 613,636\n",
      "Trainable params: 613,636\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.build(np.array([X_train_1,X_train_2,X_train_3]).shape)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdcheck = ModelCheckpoint(\"trained_models/best_model_val_acc{val_acc:.4f}.h5\", monitor='val_f1', save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 30160 samples, validate on 2755 samples\n",
      "Epoch 1/20\n",
      "30160/30160 [==============================] - 66s 2ms/step - loss: 2.5574 - acc: 0.7333 - f1: 0.6799 - val_loss: 0.6422 - val_acc: 0.7659 - val_f1: 0.6202\n",
      "Epoch 2/20\n",
      "30160/30160 [==============================] - 63s 2ms/step - loss: 1.7140 - acc: 0.8388 - f1: 0.8230 - val_loss: 0.5437 - val_acc: 0.8120 - val_f1: 0.6327\n",
      "Epoch 3/20\n",
      "30160/30160 [==============================] - 66s 2ms/step - loss: 1.5273 - acc: 0.8591 - f1: 0.8439 - val_loss: 0.5945 - val_acc: 0.7993 - val_f1: 0.6078\n",
      "Epoch 4/20\n",
      "30160/30160 [==============================] - 95s 3ms/step - loss: 1.3858 - acc: 0.8708 - f1: 0.8579 - val_loss: 0.4461 - val_acc: 0.8505 - val_f1: 0.6485\n",
      "Epoch 5/20\n",
      "30160/30160 [==============================] - 91s 3ms/step - loss: 1.3037 - acc: 0.8794 - f1: 0.8681 - val_loss: 0.5287 - val_acc: 0.8196 - val_f1: 0.6272\n",
      "Epoch 6/20\n",
      "30160/30160 [==============================] - 89s 3ms/step - loss: 1.2201 - acc: 0.8842 - f1: 0.8733 - val_loss: 0.6120 - val_acc: 0.7993 - val_f1: 0.6114\n",
      "Epoch 7/20\n",
      "30160/30160 [==============================] - 82s 3ms/step - loss: 1.1579 - acc: 0.8913 - f1: 0.8807 - val_loss: 0.5471 - val_acc: 0.8152 - val_f1: 0.6229\n",
      "Epoch 8/20\n",
      "30160/30160 [==============================] - 91s 3ms/step - loss: 1.1167 - acc: 0.8958 - f1: 0.8852 - val_loss: 0.6809 - val_acc: 0.7739 - val_f1: 0.5817\n",
      "Epoch 9/20\n",
      "30160/30160 [==============================] - 85s 3ms/step - loss: 1.0392 - acc: 0.9005 - f1: 0.8917 - val_loss: 0.6088 - val_acc: 0.8073 - val_f1: 0.6077\n",
      "Epoch 10/20\n",
      "30160/30160 [==============================] - 80s 3ms/step - loss: 1.0244 - acc: 0.9021 - f1: 0.8934 - val_loss: 0.5604 - val_acc: 0.8178 - val_f1: 0.6203\n",
      "Epoch 11/20\n",
      "30160/30160 [==============================] - 85s 3ms/step - loss: 0.9870 - acc: 0.9070 - f1: 0.8982 - val_loss: 0.5750 - val_acc: 0.8171 - val_f1: 0.6061\n",
      "Epoch 12/20\n",
      "30160/30160 [==============================] - 89s 3ms/step - loss: 0.9479 - acc: 0.9095 - f1: 0.9021 - val_loss: 0.5904 - val_acc: 0.8131 - val_f1: 0.6133\n",
      "Epoch 13/20\n",
      "30160/30160 [==============================] - 101s 3ms/step - loss: 0.9437 - acc: 0.9092 - f1: 0.9010 - val_loss: 0.6593 - val_acc: 0.7808 - val_f1: 0.5860\n",
      "Epoch 14/20\n",
      "30160/30160 [==============================] - 100s 3ms/step - loss: 0.9054 - acc: 0.9134 - f1: 0.9066 - val_loss: 0.5589 - val_acc: 0.8287 - val_f1: 0.6223\n",
      "Epoch 15/20\n",
      "30160/30160 [==============================] - 72s 2ms/step - loss: 0.8908 - acc: 0.9149 - f1: 0.9074 - val_loss: 0.6522 - val_acc: 0.7960 - val_f1: 0.5977\n",
      "Epoch 16/20\n",
      "30160/30160 [==============================] - 80s 3ms/step - loss: 0.8569 - acc: 0.9160 - f1: 0.9089 - val_loss: 0.6660 - val_acc: 0.7985 - val_f1: 0.5917\n",
      "Epoch 17/20\n",
      "30160/30160 [==============================] - 81s 3ms/step - loss: 0.8412 - acc: 0.9189 - f1: 0.9113 - val_loss: 0.6659 - val_acc: 0.7964 - val_f1: 0.5900\n",
      "Epoch 18/20\n",
      "30160/30160 [==============================] - 90s 3ms/step - loss: 0.8422 - acc: 0.9204 - f1: 0.9125 - val_loss: 0.7050 - val_acc: 0.7869 - val_f1: 0.5900\n",
      "Epoch 19/20\n",
      "30160/30160 [==============================] - 88s 3ms/step - loss: 0.8174 - acc: 0.9217 - f1: 0.9151 - val_loss: 0.6589 - val_acc: 0.8083 - val_f1: 0.6106\n",
      "Epoch 20/20\n",
      "30160/30160 [==============================] - 71s 2ms/step - loss: 0.8219 - acc: 0.9194 - f1: 0.9127 - val_loss: 0.6355 - val_acc: 0.8083 - val_f1: 0.6059\n"
     ]
    }
   ],
   "source": [
    "Y_train = np.array(Y_train)\n",
    "total = len(Y_train)\n",
    "try:\n",
    "    history = model.fit([X_train_1,X_train_2,X_train_3], Y_train,\n",
    "                        validation_data=([X_test_1,X_test_2,X_test_3], Y_test),\n",
    "                        epochs=10, verbose=1, batch_size=batch_size,\n",
    "                        class_weight={\n",
    "                            0: total / len(np.where(Y_train[:,0]==1.0)[0]),\n",
    "                            1: total / len(np.where(Y_train[:,1]==1.0)[0]),\n",
    "                            2: total / len(np.where(Y_train[:,2]==1.0)[0]),\n",
    "                            3: total / len(np.where(Y_train[:,3]==1.0)[0]),\n",
    "                        },callbacks=[mdcheck],shuffle=True)\n",
    "except KeyboardInterrupt:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>turn1</th>\n",
       "      <th>turn2</th>\n",
       "      <th>turn3</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>then dont ask me</td>\n",
       "      <td>youre a guy not as if you would understand</td>\n",
       "      <td>im not a guy fuck off</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>mixed things such as   ??</td>\n",
       "      <td>the things you do .  .</td>\n",
       "      <td>have you seen minions   ??</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>today ism very happy</td>\n",
       "      <td>and ism happy for you</td>\n",
       "      <td>i will be marry</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>noah bring me some</td>\n",
       "      <td>left it there oops</td>\n",
       "      <td>orb</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>it is thoo</td>\n",
       "      <td>i said soon master .  .</td>\n",
       "      <td>he is pressuring me</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id                       turn1  \\\n",
       "0  0          then dont ask me     \n",
       "1  1  mixed things such as   ??    \n",
       "2  2      today ism very happy     \n",
       "3  3        noah bring me some     \n",
       "4  4                it is thoo     \n",
       "\n",
       "                                          turn2                        turn3  \\\n",
       "0  youre a guy not as if you would understand        im not a guy fuck off     \n",
       "1                        the things you do .  .  have you seen minions   ??    \n",
       "2                      and ism happy for you               i will be marry     \n",
       "3                          left it there oops                          orb     \n",
       "4                       i said soon master .  .        he is pressuring me     \n",
       "\n",
       "    label  \n",
       "0   angry  \n",
       "1  others  \n",
       "2   happy  \n",
       "3  others  \n",
       "4  others  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = functions.parse_file(r\"raw_data/EmoContext/devwithlabels2.txt\", \"EmoContext\")\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2755/2755 [==============================] - 2s 885us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([3.2564381e-03, 9.2381379e-07, 8.0551277e-04, 9.9593711e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = model.predict([X_test_1,X_test_2,X_test_3], batch_size=64, verbose=1)\n",
    "res[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "revers_words = {0:\"others\", 1:\"angry\", 2:\"sad\", 3:\"happy\"}\n",
    "\n",
    "def softmax_convert(res):\n",
    "    max_i = 0\n",
    "    max_v = 0\n",
    "    for i in range(0,4):\n",
    "        if res[i] > max_v:\n",
    "            max_v = res[i]\n",
    "            max_i = i\n",
    "    return revers_words[max_i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for r in res:\n",
    "    results.append(softmax_convert(r))\n",
    "    \n",
    "df_test['label'] = results\n",
    "df_test.head(50)\n",
    "df_test.to_csv(\"separate_goodies.txt\",index=False , sep=\"\\t\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36-test",
   "language": "python",
   "name": "py36-test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
