{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from keras.layers import Dropout, Input, Concatenate,concatenate\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Embedding, LSTM\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras import optimizers\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import tensorflow as tf\n",
    "\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(y_true, y_pred):\n",
    "    y_pred = K.round(y_pred)\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return K.mean(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>turn1</th>\n",
       "      <th>turn2</th>\n",
       "      <th>turn3</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Don't worry  I'm girl</td>\n",
       "      <td>hmm how do I know if you are</td>\n",
       "      <td>What's ur name?</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>When did I?</td>\n",
       "      <td>saw many times i think -_-</td>\n",
       "      <td>No. I never saw you</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>By</td>\n",
       "      <td>by Google Chrome</td>\n",
       "      <td>Where you live</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>U r ridiculous</td>\n",
       "      <td>I might be ridiculous but I am telling the truth.</td>\n",
       "      <td>U little disgusting whore</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Just for time pass</td>\n",
       "      <td>wt do u do 4 a living then</td>\n",
       "      <td>Maybe</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id                  turn1  \\\n",
       "0  0  Don't worry  I'm girl   \n",
       "1  1            When did I?   \n",
       "2  2                     By   \n",
       "3  3         U r ridiculous   \n",
       "4  4     Just for time pass   \n",
       "\n",
       "                                               turn2  \\\n",
       "0                       hmm how do I know if you are   \n",
       "1                         saw many times i think -_-   \n",
       "2                                   by Google Chrome   \n",
       "3  I might be ridiculous but I am telling the truth.   \n",
       "4                         wt do u do 4 a living then   \n",
       "\n",
       "                       turn3   label  \n",
       "0            What's ur name?  others  \n",
       "1        No. I never saw you   angry  \n",
       "2             Where you live  others  \n",
       "3  U little disgusting whore   angry  \n",
       "4                      Maybe  others  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import *\n",
    "df = functions.parse_file(r\"raw_data/EmoContext/train2.txt\", \"EmoContext\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = []\n",
    "for idx,row in df.iterrows():\n",
    "    text_data.append(\"{}. {}. {}.\".format(row['turn1'], row['turn2'], row['turn3']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "NR_WORDS = 5000\n",
    "MAX_PROP_LENGTH = 128\n",
    "tokenizer = Tokenizer(num_words=NR_WORDS, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
    "                                   lower=True,split=' ')\n",
    "\n",
    "tokenizer.fit_on_texts(text_data)\n",
    "\n",
    "X_train_1 = tokenizer.texts_to_sequences(df[\"turn1\"])\n",
    "X_train_1 = pad_sequences(X_train_1, maxlen = MAX_PROP_LENGTH)\n",
    "\n",
    "X_train_2 = tokenizer.texts_to_sequences(df[\"turn2\"])\n",
    "X_train_2 = pad_sequences(X_train_2, maxlen = MAX_PROP_LENGTH)\n",
    "\n",
    "X_train_3 = tokenizer.texts_to_sequences(df[\"turn3\"])\n",
    "X_train_3 = pad_sequences(X_train_3, maxlen = MAX_PROP_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_vector(word,label=None):\n",
    "    words = {\"others\": 0, \"angry\": 1, \"sad\":2, \"happy\": 3}\n",
    "    if label == None:\n",
    "        y = [0,0,0,0]\n",
    "        y[words[word]] = 1\n",
    "        return y\n",
    "    if label == word:\n",
    "        return [1,0]\n",
    "    return [0,1]\n",
    "\n",
    "Y_train = []\n",
    "\n",
    "for idx,row in df.iterrows():\n",
    "    Y_train.append(one_hot_vector(row['label']))\n",
    "\n",
    "Y_train = np.array(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>turn1</th>\n",
       "      <th>turn2</th>\n",
       "      <th>turn3</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Then dont ask me</td>\n",
       "      <td>YOURE A GUY NOT AS IF YOU WOULD UNDERSTAND</td>\n",
       "      <td>IM NOT A GUY FUCK OFF</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Mixed things  such as??</td>\n",
       "      <td>the things you do.</td>\n",
       "      <td>Have you seen minions??</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Today I'm very happy</td>\n",
       "      <td>and I'm happy for you ❤</td>\n",
       "      <td>I will be marry</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Woah bring me some</td>\n",
       "      <td>left it there oops</td>\n",
       "      <td>Brb</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>it is thooooo</td>\n",
       "      <td>I said soon master.</td>\n",
       "      <td>he is pressuring me</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id                    turn1                                       turn2  \\\n",
       "0  0         Then dont ask me  YOURE A GUY NOT AS IF YOU WOULD UNDERSTAND   \n",
       "1  1  Mixed things  such as??                          the things you do.   \n",
       "2  2     Today I'm very happy                     and I'm happy for you ❤   \n",
       "3  3       Woah bring me some                          left it there oops   \n",
       "4  4            it is thooooo                         I said soon master.   \n",
       "\n",
       "                     turn3   label  \n",
       "0    IM NOT A GUY FUCK OFF   angry  \n",
       "1  Have you seen minions??  others  \n",
       "2          I will be marry   happy  \n",
       "3                      Brb  others  \n",
       "4      he is pressuring me  others  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = functions.parse_file(r\"raw_data/EmoContext/devwithlabels2.txt\", \"EmoContext\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = []\n",
    "for idx,row in df.iterrows():\n",
    "    text_data.append(\"{}. {}. {}.\".format(row['turn1'], row['turn2'], row['turn3']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=NR_WORDS, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
    "                                   lower=True,split=' ')\n",
    "\n",
    "tokenizer.fit_on_texts(text_data)\n",
    "\n",
    "X_test_1 = tokenizer.texts_to_sequences(df[\"turn1\"])\n",
    "X_test_1 = pad_sequences(X_test_1, maxlen = MAX_PROP_LENGTH)\n",
    "\n",
    "X_test_2 = tokenizer.texts_to_sequences(df[\"turn2\"])\n",
    "X_test_2 = pad_sequences(X_test_2, maxlen = MAX_PROP_LENGTH)\n",
    "\n",
    "X_test_3 = tokenizer.texts_to_sequences(df[\"turn3\"])\n",
    "X_test_3 = pad_sequences(X_test_3, maxlen = MAX_PROP_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_vector(word,label=None):\n",
    "    words = {\"others\": 0, \"angry\": 1, \"sad\":2, \"happy\": 3}\n",
    "    if label == None:\n",
    "        y = [0,0,0,0]\n",
    "        y[words[word]] = 1\n",
    "        return y\n",
    "    if label == word:\n",
    "        return [1,0]\n",
    "    return [0,1]\n",
    "\n",
    "Y_test = []\n",
    "\n",
    "for idx,row in df.iterrows():\n",
    "    Y_test.append(one_hot_vector(row['label']))\n",
    "\n",
    "Y_test = np.array(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 128\n",
    "lstm_out = 64\n",
    "batch_size = 64\n",
    "\n",
    "adam = optimizers.Adam(lr=0.01)\n",
    "rmsprop = optimizers.RMSprop(lr=0.005, rho=0.9, epsilon=None, decay=0.0)\n",
    "\n",
    "I_1 = Input(shape=X_train_1.shape[1:])\n",
    "O_1 = Embedding(NR_WORDS, embed_dim,input_length = X_train_1.shape[1])(I_1)\n",
    "O_1 = LSTM(lstm_out, dropout=0.5)(O_1)\n",
    "\n",
    "I_2 = Input(shape=X_train_2.shape[1:])\n",
    "O_2 = Embedding(NR_WORDS, embed_dim,input_length = X_train_2.shape[1])(I_2)\n",
    "O_2 = LSTM(lstm_out, dropout=0.5)(O_2)\n",
    "\n",
    "I_3 = Input(shape=X_train_3.shape[1:])\n",
    "O_3 = Embedding(NR_WORDS, embed_dim,input_length = X_train_3.shape[1])(I_3)\n",
    "O_3 = LSTM(lstm_out, dropout=0.5)(O_3)\n",
    "\n",
    "result = concatenate([O_1,O_2,O_3])\n",
    "result = Dense(128)(result)\n",
    "result = Dropout(0.4)(result)\n",
    "result = Dense(64)(result)\n",
    "result = Dropout(0.4)(result)\n",
    "result = Dense(4,activation='softmax')(result)\n",
    "model = Model(inputs=[I_1,I_2,I_3], outputs=result,name=\"separate_embedings_model\")\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer=rmsprop, metrics = ['accuracy', f1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 128)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 128)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 128)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 128, 128)     640000      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 128, 128)     640000      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 128, 128)     640000      input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 64)           49408       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   (None, 64)           49408       embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   (None, 64)           49408       embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 192)          0           lstm_1[0][0]                     \n",
      "                                                                 lstm_2[0][0]                     \n",
      "                                                                 lstm_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          24704       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 128)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 64)           8256        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 64)           0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 4)            260         dropout_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 2,101,444\n",
      "Trainable params: 2,101,444\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.build(np.array([X_train_1,X_train_2,X_train_3]).shape)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdcheck = ModelCheckpoint(\"trained_models/best_model_val_acc{val_acc:.4f}.h5\", monitor='val_f1', save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 30160 samples, validate on 2755 samples\n",
      "Epoch 1/20\n",
      "30160/30160 [==============================] - 209s 7ms/step - loss: 2.4726 - acc: 0.7402 - f1: 0.6897 - val_loss: 1.4324 - val_acc: 0.5485 - val_f1: 0.2219\n",
      "Epoch 2/20\n",
      "30160/30160 [==============================] - 204s 7ms/step - loss: 1.4615 - acc: 0.8611 - f1: 0.8427 - val_loss: 1.4733 - val_acc: 0.5851 - val_f1: 0.2381\n",
      "Epoch 3/20\n",
      "30160/30160 [==============================] - 203s 7ms/step - loss: 1.1948 - acc: 0.8887 - f1: 0.8751 - val_loss: 1.5730 - val_acc: 0.5815 - val_f1: 0.2356\n",
      "Epoch 4/20\n",
      "15328/30160 [==============>...............] - ETA: 1:43 - loss: 0.9930 - acc: 0.9056 - f1: 0.8947"
     ]
    }
   ],
   "source": [
    "Y_train = np.array(Y_train)\n",
    "total = len(Y_train)\n",
    "try:\n",
    "    history = model.fit([X_train_1,X_train_2,X_train_3], Y_train,\n",
    "                        validation_data=([X_test_1,X_test_2,X_test_3], Y_test),\n",
    "                        epochs=20, verbose=1, batch_size=batch_size,\n",
    "                        class_weight={\n",
    "                            0: total / len(np.where(Y_train[:,0]==1.0)[0]),\n",
    "                            1: total / len(np.where(Y_train[:,1]==1.0)[0]),\n",
    "                            2: total / len(np.where(Y_train[:,2]==1.0)[0]),\n",
    "                            3: total / len(np.where(Y_train[:,3]==1.0)[0]),\n",
    "                        },callbacks=[mdcheck],shuffle=True)\n",
    "except KeyboardInterrupt:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>turn1</th>\n",
       "      <th>turn2</th>\n",
       "      <th>turn3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Then dont ask me</td>\n",
       "      <td>YOURE A GUY NOT AS IF YOU WOULD UNDERSTAND</td>\n",
       "      <td>IM NOT A GUY FUCK OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Mixed things  such as??</td>\n",
       "      <td>the things you do.</td>\n",
       "      <td>Have you seen minions??</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Today I'm very happy</td>\n",
       "      <td>and I'm happy for you ❤</td>\n",
       "      <td>I will be marry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Woah bring me some</td>\n",
       "      <td>left it there oops</td>\n",
       "      <td>Brb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>it is thooooo</td>\n",
       "      <td>I said soon master.</td>\n",
       "      <td>he is pressuring me</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id                    turn1                                       turn2  \\\n",
       "0  0         Then dont ask me  YOURE A GUY NOT AS IF YOU WOULD UNDERSTAND   \n",
       "1  1  Mixed things  such as??                          the things you do.   \n",
       "2  2     Today I'm very happy                     and I'm happy for you ❤   \n",
       "3  3       Woah bring me some                          left it there oops   \n",
       "4  4            it is thooooo                         I said soon master.   \n",
       "\n",
       "                     turn3  \n",
       "0    IM NOT A GUY FUCK OFF  \n",
       "1  Have you seen minions??  \n",
       "2          I will be marry  \n",
       "3                      Brb  \n",
       "4      he is pressuring me  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = functions.parse_file(r\"raw_data/EmoContext/devwithlabels2.txt\", \"EmoContext\")\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2755/2755 [==============================] - 4s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.07798924, 0.03819224, 0.87913007, 0.00468843], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = model.predict([X_test_1,X_test_2,X_test_3], batch_size=64, verbose=1)\n",
    "res[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "revers_words = {0:\"others\", 1:\"angry\", 2:\"sad\", 3:\"happy\"}\n",
    "\n",
    "def softmax_convert(res):\n",
    "    max_i = 0\n",
    "    max_v = 0\n",
    "    for i in range(0,4):\n",
    "        if res[i] > max_v:\n",
    "            max_v = res[i]\n",
    "            max_i = i\n",
    "    return revers_words[max_i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for r in res:\n",
    "    results.append(softmax_convert(r))\n",
    "    \n",
    "df_test['label'] = results\n",
    "df_test.head(50)\n",
    "df_test.to_csv(\"lstm_normal_12_epochs_cv.txt\",index=False , sep=\"\\t\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36-test",
   "language": "python",
   "name": "py36-test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
