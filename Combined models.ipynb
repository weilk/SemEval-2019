{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from keras.layers import Dropout\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential,clone_model\n",
    "from keras.layers import Dense, Embedding, LSTM\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras import optimizers\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import tensorflow as tf\n",
    "\n",
    "import keras.backend as K\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>turn1</th>\n",
       "      <th>turn2</th>\n",
       "      <th>turn3</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Don't worry  I'm girl</td>\n",
       "      <td>hmm how do I know if you are</td>\n",
       "      <td>What's ur name?</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>When did I?</td>\n",
       "      <td>saw many times i think -_-</td>\n",
       "      <td>No. I never saw you</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>By</td>\n",
       "      <td>by Google Chrome</td>\n",
       "      <td>Where you live</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>U r ridiculous</td>\n",
       "      <td>I might be ridiculous but I am telling the truth.</td>\n",
       "      <td>U little disgusting whore</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Just for time pass</td>\n",
       "      <td>wt do u do 4 a living then</td>\n",
       "      <td>Maybe</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id                  turn1  \\\n",
       "0  0  Don't worry  I'm girl   \n",
       "1  1            When did I?   \n",
       "2  2                     By   \n",
       "3  3         U r ridiculous   \n",
       "4  4     Just for time pass   \n",
       "\n",
       "                                               turn2  \\\n",
       "0                       hmm how do I know if you are   \n",
       "1                         saw many times i think -_-   \n",
       "2                                   by Google Chrome   \n",
       "3  I might be ridiculous but I am telling the truth.   \n",
       "4                         wt do u do 4 a living then   \n",
       "\n",
       "                       turn3   label  \n",
       "0            What's ur name?  others  \n",
       "1        No. I never saw you   angry  \n",
       "2             Where you live  others  \n",
       "3  U little disgusting whore   angry  \n",
       "4                      Maybe  others  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = functions.parse_file(r\"raw_data/EmoContext/train2.txt\", \"EmoContext\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = []\n",
    "for idx,row in df.iterrows():\n",
    "    text_data.append(\"{}. {}. {}.\".format(row['turn1'], row['turn2'], row['turn3']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "NR_WORDS = 8000\n",
    "MAX_PROP_LENGTH = 128\n",
    "tokenizer = Tokenizer(num_words=NR_WORDS, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
    "                                   lower=True,split=' ')\n",
    "\n",
    "tokenizer.fit_on_texts(text_data)\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(text_data)\n",
    "X_train = pad_sequences(X_train, maxlen = MAX_PROP_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_vector(word,label=None):\n",
    "    words = {\"others\": 0, \"angry\": 1, \"sad\":2, \"happy\": 3}\n",
    "    if label == None:\n",
    "        y = [0,0,0,0]\n",
    "        y[words[word]] = 1\n",
    "        return y\n",
    "    if label == word:\n",
    "        return [1,0]\n",
    "    return [0,1]\n",
    "\n",
    "Y_train = []\n",
    "\n",
    "for idx,row in df.iterrows():\n",
    "    Y_train.append(one_hot_vector(row['label']))\n",
    "\n",
    "Y_train = np.array(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>turn1</th>\n",
       "      <th>turn2</th>\n",
       "      <th>turn3</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Then dont ask me</td>\n",
       "      <td>YOURE A GUY NOT AS IF YOU WOULD UNDERSTAND</td>\n",
       "      <td>IM NOT A GUY FUCK OFF</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Mixed things  such as??</td>\n",
       "      <td>the things you do.</td>\n",
       "      <td>Have you seen minions??</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Today I'm very happy</td>\n",
       "      <td>and I'm happy for you ❤</td>\n",
       "      <td>I will be marry</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Woah bring me some</td>\n",
       "      <td>left it there oops</td>\n",
       "      <td>Brb</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>it is thooooo</td>\n",
       "      <td>I said soon master.</td>\n",
       "      <td>he is pressuring me</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id                    turn1                                       turn2  \\\n",
       "0  0         Then dont ask me  YOURE A GUY NOT AS IF YOU WOULD UNDERSTAND   \n",
       "1  1  Mixed things  such as??                          the things you do.   \n",
       "2  2     Today I'm very happy                     and I'm happy for you ❤   \n",
       "3  3       Woah bring me some                          left it there oops   \n",
       "4  4            it is thooooo                         I said soon master.   \n",
       "\n",
       "                     turn3   label  \n",
       "0    IM NOT A GUY FUCK OFF   angry  \n",
       "1  Have you seen minions??  others  \n",
       "2          I will be marry   happy  \n",
       "3                      Brb  others  \n",
       "4      he is pressuring me  others  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = functions.parse_file(r\"raw_data/EmoContext/devwithlabels2.txt\", \"EmoContext\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = []\n",
    "for idx,row in df.iterrows():\n",
    "    text_data.append(\"{}. {}. {}.\".format(row['turn1'], row['turn2'], row['turn3']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizer = Tokenizer(num_words=NR_WORDS, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
    "#                                   lower=True,split=' ')\n",
    "\n",
    "#tokenizer.fit_on_texts(text_data)\n",
    "\n",
    "X_test = tokenizer.texts_to_sequences(text_data)\n",
    "X_test = pad_sequences(X_test, maxlen = MAX_PROP_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_vector(word,label=None):\n",
    "    words = {\"others\": 0, \"angry\": 1, \"sad\":2, \"happy\": 3}\n",
    "    if label == None:\n",
    "        y = [0,0,0,0]\n",
    "        y[words[word]] = 1\n",
    "        return y\n",
    "    if label == word:\n",
    "        return [1,0]\n",
    "    return [0,1]\n",
    "\n",
    "Y_test = []\n",
    "\n",
    "for idx,row in df.iterrows():\n",
    "    Y_test.append(one_hot_vector(row['label']))\n",
    "\n",
    "Y_test = np.array(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model models\\angry_sequential_1_model.json from disk\n",
      "Loaded model models\\happy_sequential_1_model.json from disk\n",
      "Loaded model models\\others_model_model.json from disk\n",
      "Loaded model models\\sad_sequential_1_model.json from disk\n",
      "Loaded model models\\sin_sequential_1_model.json from disk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python36\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"de...)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "final_loaded_models = load_models()\n",
    "merged_layer, input_layers = create_final_layers(final_loaded_models)\n",
    "merged_layer = Dense(8)(merged_layer)\n",
    "merged_layer = Dropout(0.5)(merged_layer)\n",
    "merged_layer = Dense(8)(merged_layer)\n",
    "merged_layer = Dropout(0.5)(merged_layer)\n",
    "merged_layer = Dense(8)(merged_layer)\n",
    "merged_layer = Dropout(0.5)(merged_layer)\n",
    "merged_layer = Dense(4, activation='softmax')(merged_layer)\n",
    "merged_model = Model(inputs=input_layers, output=merged_layer,name=\"merged_model\")\n",
    "merged_model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy',f1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "angry_boosting_embeding_input ( (None, 200)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "happy_boosting_embeding_input ( (None, 200)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "others_boosting_embeding_input  (None, 200)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sad_boosting_embeding_input (In (None, 200)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sin_model_input (InputLayer)    (None, 200)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "angry_sequential_1_model.json_a (None, 200, 128)     640000      angry_boosting_embeding_input[0][\n",
      "__________________________________________________________________________________________________\n",
      "happy_sequential_1_model.json_h (None, 200, 128)     640000      happy_boosting_embeding_input[0][\n",
      "__________________________________________________________________________________________________\n",
      "others_model_model.json_others_ (None, 200, 128)     640000      others_boosting_embeding_input[0]\n",
      "__________________________________________________________________________________________________\n",
      "sad_sequential_1_model.json_sad (None, 200, 128)     640000      sad_boosting_embeding_input[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "sin_sequential_1_model.json_sin (None, 200, 128)     640000      sin_model_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "angry_sequential_1_model.json_l (None, 32)           20608       angry_sequential_1_model.json_ang\n",
      "__________________________________________________________________________________________________\n",
      "happy_sequential_1_model.json_l (None, 32)           20608       happy_sequential_1_model.json_hap\n",
      "__________________________________________________________________________________________________\n",
      "others_model_model.json_lstm_1  (None, 32)           20608       others_model_model.json_others_bo\n",
      "__________________________________________________________________________________________________\n",
      "sad_sequential_1_model.json_lst (None, 32)           20608       sad_sequential_1_model.json_sad_b\n",
      "__________________________________________________________________________________________________\n",
      "sin_sequential_1_model.json_lst (None, 32)           20608       sin_sequential_1_model.json_sin_m\n",
      "__________________________________________________________________________________________________\n",
      "angry_sequential_1_model.json_d (None, 2)            66          angry_sequential_1_model.json_lst\n",
      "__________________________________________________________________________________________________\n",
      "happy_sequential_1_model.json_d (None, 2)            66          happy_sequential_1_model.json_lst\n",
      "__________________________________________________________________________________________________\n",
      "others_model_model.json_dense_1 (None, 2)            66          others_model_model.json_lstm_1[0]\n",
      "__________________________________________________________________________________________________\n",
      "sad_sequential_1_model.json_den (None, 2)            66          sad_sequential_1_model.json_lstm_\n",
      "__________________________________________________________________________________________________\n",
      "sin_sequential_1_model.json_den (None, 4)            132         sin_sequential_1_model.json_lstm_\n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 12)           0           angry_sequential_1_model.json_den\n",
      "                                                                 happy_sequential_1_model.json_den\n",
      "                                                                 others_model_model.json_dense_1[0\n",
      "                                                                 sad_sequential_1_model.json_dense\n",
      "                                                                 sin_sequential_1_model.json_dense\n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 8)            104         concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 8)            0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 8)            72          dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 8)            0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 8)            72          dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 8)            0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 4)            36          dropout_3[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 3,303,720\n",
      "Trainable params: 284\n",
      "Non-trainable params: 3,303,436\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "merged_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdcheck = ModelCheckpoint(\"trained_models/best_model_val_acc{val_acc:.4f}.h5\", monitor='val_f1', save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 30160 samples, validate on 2755 samples\n",
      "Epoch 1/10\n",
      "30160/30160 [==============================] - 70s 2ms/step - loss: 3.9035 - acc: 0.5672 - f1: 0.4705 - val_loss: 1.8513 - val_acc: 0.4868 - val_f1: 0.2175\n",
      "Epoch 2/10\n",
      "30160/30160 [==============================] - 70s 2ms/step - loss: 2.3993 - acc: 0.7769 - f1: 0.7257 - val_loss: 2.6100 - val_acc: 0.4947 - val_f1: 0.2282\n",
      "Epoch 3/10\n",
      "30160/30160 [==============================] - 72s 2ms/step - loss: 2.1117 - acc: 0.8180 - f1: 0.7722 - val_loss: 2.7948 - val_acc: 0.4991 - val_f1: 0.2330\n",
      "Epoch 4/10\n",
      "30160/30160 [==============================] - 71s 2ms/step - loss: 1.9625 - acc: 0.8393 - f1: 0.7974 - val_loss: 3.1064 - val_acc: 0.4955 - val_f1: 0.2316\n",
      "Epoch 5/10\n",
      "30160/30160 [==============================] - 73s 2ms/step - loss: 1.9152 - acc: 0.8529 - f1: 0.8146 - val_loss: 3.1765 - val_acc: 0.5013 - val_f1: 0.2327\n",
      "Epoch 6/10\n",
      "30160/30160 [==============================] - 71s 2ms/step - loss: 1.8528 - acc: 0.8632 - f1: 0.8293 - val_loss: 3.2743 - val_acc: 0.4980 - val_f1: 0.2315\n",
      "Epoch 7/10\n",
      "30160/30160 [==============================] - 80s 3ms/step - loss: 1.8268 - acc: 0.8686 - f1: 0.8352 - val_loss: 3.3808 - val_acc: 0.5049 - val_f1: 0.2335\n",
      "Epoch 8/10\n",
      "30160/30160 [==============================] - 122s 4ms/step - loss: 1.7488 - acc: 0.8776 - f1: 0.8477 - val_loss: 3.5661 - val_acc: 0.4995 - val_f1: 0.2316\n",
      "Epoch 9/10\n",
      "30160/30160 [==============================] - 82s 3ms/step - loss: 1.7525 - acc: 0.8762 - f1: 0.8457 - val_loss: 3.4788 - val_acc: 0.5082 - val_f1: 0.2353\n",
      "Epoch 10/10\n",
      "30160/30160 [==============================] - 122s 4ms/step - loss: 1.7434 - acc: 0.8802 - f1: 0.8525 - val_loss: 3.5607 - val_acc: 0.4984 - val_f1: 0.2315\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "Y_train = np.array(Y_train)\n",
    "total = len(Y_train)\n",
    "history = merged_model.fit([X_train,X_train,X_train,X_train,X_train], Y_train,\n",
    "                    validation_data=([X_test,X_test,X_test,X_test,X_test], Y_test),\n",
    "                    epochs=10, verbose=1, batch_size=batch_size,class_weight={\n",
    "                        0: total / len(np.where(Y_train[:,0]==1.0)[0]),\n",
    "                        1: total / len(np.where(Y_train[:,1]==1.0)[0]),\n",
    "                        2: total / len(np.where(Y_train[:,2]==1.0)[0]),\n",
    "                        3: total / len(np.where(Y_train[:,3]==1.0)[0]),\n",
    "                    },callbacks=[mdcheck],\n",
    "                          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(merged_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>turn1</th>\n",
       "      <th>turn2</th>\n",
       "      <th>turn3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Then dont ask me</td>\n",
       "      <td>YOURE A GUY NOT AS IF YOU WOULD UNDERSTAND</td>\n",
       "      <td>IM NOT A GUY FUCK OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Mixed things  such as??</td>\n",
       "      <td>the things you do.</td>\n",
       "      <td>Have you seen minions??</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Today I'm very happy</td>\n",
       "      <td>and I'm happy for you ❤</td>\n",
       "      <td>I will be marry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Woah bring me some</td>\n",
       "      <td>left it there oops</td>\n",
       "      <td>Brb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>it is thooooo</td>\n",
       "      <td>I said soon master.</td>\n",
       "      <td>he is pressuring me</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id                    turn1                                       turn2  \\\n",
       "0  0         Then dont ask me  YOURE A GUY NOT AS IF YOU WOULD UNDERSTAND   \n",
       "1  1  Mixed things  such as??                          the things you do.   \n",
       "2  2     Today I'm very happy                     and I'm happy for you ❤   \n",
       "3  3       Woah bring me some                          left it there oops   \n",
       "4  4            it is thooooo                         I said soon master.   \n",
       "\n",
       "                     turn3  \n",
       "0    IM NOT A GUY FUCK OFF  \n",
       "1  Have you seen minions??  \n",
       "2          I will be marry  \n",
       "3                      Brb  \n",
       "4      he is pressuring me  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = functions.parse_file(r\"raw_data/EmoContext/devwithlabels2.txt\", \"EmoContext\")\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-2d830d318057>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mtext_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{}. {}. {}.\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'turn1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'turn2'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'turn3'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "text_data = []\n",
    "\n",
    "for idx,row in df_test.iterrows():\n",
    "    text_data.append(\"{}. {}. {}.\".format(row['turn1'], row['turn2'], row['turn3']))\n",
    "\n",
    "res = model.predict(X_test, batch_size=64, verbose=1)\n",
    "res[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "revers_words = {0:\"others\", 1:\"angry\", 2:\"sad\", 3:\"happy\"}\n",
    "\n",
    "def softmax_convert(res):\n",
    "    max_i = 0\n",
    "    max_v = 0\n",
    "    for i in range(0,4):\n",
    "        if res[i] > max_v:\n",
    "            max_v = res[i]\n",
    "            max_i = i\n",
    "    return revers_words[max_i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for r in res:\n",
    "    results.append(softmax_convert(r))\n",
    "    \n",
    "df_test['label'] = results\n",
    "df_test.head(50)\n",
    "df_test.to_csv(\"combined_models_submission.txt\",index=False , sep=\"\\t\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36-test",
   "language": "python",
   "name": "py36-test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
